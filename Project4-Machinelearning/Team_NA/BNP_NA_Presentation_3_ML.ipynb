{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# machine learning\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import cross_validation\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v9</th>\n",
       "      <th>v14</th>\n",
       "      <th>...</th>\n",
       "      <th>v129_0</th>\n",
       "      <th>v129_1</th>\n",
       "      <th>v129_11</th>\n",
       "      <th>v129_2</th>\n",
       "      <th>v129_3</th>\n",
       "      <th>v129_4</th>\n",
       "      <th>v129_5</th>\n",
       "      <th>v129_6</th>\n",
       "      <th>v129_7</th>\n",
       "      <th>v129_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.335739</td>\n",
       "      <td>8.727474</td>\n",
       "      <td>3.921026</td>\n",
       "      <td>7.915266</td>\n",
       "      <td>2.599278</td>\n",
       "      <td>3.176895</td>\n",
       "      <td>9.999999</td>\n",
       "      <td>11.636387</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.630686</td>\n",
       "      <td>7.464411</td>\n",
       "      <td>4.145098</td>\n",
       "      <td>9.191265</td>\n",
       "      <td>2.436402</td>\n",
       "      <td>2.483921</td>\n",
       "      <td>9.031859</td>\n",
       "      <td>11.636386</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.943877</td>\n",
       "      <td>5.310079</td>\n",
       "      <td>4.410969</td>\n",
       "      <td>5.326159</td>\n",
       "      <td>3.979592</td>\n",
       "      <td>3.928571</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>9.603542</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.797415</td>\n",
       "      <td>8.304757</td>\n",
       "      <td>4.225930</td>\n",
       "      <td>11.627438</td>\n",
       "      <td>2.097700</td>\n",
       "      <td>1.987549</td>\n",
       "      <td>8.965516</td>\n",
       "      <td>14.094723</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1.630686</td>\n",
       "      <td>7.464411</td>\n",
       "      <td>4.145098</td>\n",
       "      <td>8.742359</td>\n",
       "      <td>2.436402</td>\n",
       "      <td>2.483921</td>\n",
       "      <td>9.031859</td>\n",
       "      <td>10.991098</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 472 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  target        v1        v2        v4         v5        v6        v7  \\\n",
       "0   3       1  1.335739  8.727474  3.921026   7.915266  2.599278  3.176895   \n",
       "1   4       1  1.630686  7.464411  4.145098   9.191265  2.436402  2.483921   \n",
       "2   5       1  0.943877  5.310079  4.410969   5.326159  3.979592  3.928571   \n",
       "3   6       1  0.797415  8.304757  4.225930  11.627438  2.097700  1.987549   \n",
       "4   8       1  1.630686  7.464411  4.145098   8.742359  2.436402  2.483921   \n",
       "\n",
       "          v9        v14   ...    v129_0  v129_1  v129_11  v129_2  v129_3  \\\n",
       "0   9.999999  11.636387   ...         1       0        0       0       0   \n",
       "1   9.031859  11.636386   ...         1       0        0       0       0   \n",
       "2  12.666667   9.603542   ...         0       0        0       1       0   \n",
       "3   8.965516  14.094723   ...         0       1        0       0       0   \n",
       "4   9.031859  10.991098   ...         1       0        0       0       0   \n",
       "\n",
       "   v129_4  v129_5  v129_6  v129_7  v129_8  \n",
       "0       0       0       0       0       0  \n",
       "1       0       0       0       0       0  \n",
       "2       0       0       0       0       0  \n",
       "3       0       0       0       0       0  \n",
       "4       0       0       0       0       0  \n",
       "\n",
       "[5 rows x 472 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bnp = pd.read_csv('./data/BNP_cleaned3.csv')\n",
    "bnp = pd.read_csv('./data/BNP_hi_removed4.csv')\n",
    "bnp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids = bnp.iloc[:,0]\n",
    "bnp.target = bnp.iloc[:, 1]\n",
    "bnp.data = bnp.iloc[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "1    4\n",
       "2    5\n",
       "3    6\n",
       "4    8\n",
       "Name: ID, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v9</th>\n",
       "      <th>v14</th>\n",
       "      <th>v16</th>\n",
       "      <th>v18</th>\n",
       "      <th>...</th>\n",
       "      <th>v129_0</th>\n",
       "      <th>v129_1</th>\n",
       "      <th>v129_11</th>\n",
       "      <th>v129_2</th>\n",
       "      <th>v129_3</th>\n",
       "      <th>v129_4</th>\n",
       "      <th>v129_5</th>\n",
       "      <th>v129_6</th>\n",
       "      <th>v129_7</th>\n",
       "      <th>v129_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.335739</td>\n",
       "      <td>8.727474</td>\n",
       "      <td>3.921026</td>\n",
       "      <td>7.915266</td>\n",
       "      <td>2.599278</td>\n",
       "      <td>3.176895</td>\n",
       "      <td>9.999999</td>\n",
       "      <td>11.636387</td>\n",
       "      <td>8.571429</td>\n",
       "      <td>0.106720</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.630686</td>\n",
       "      <td>7.464411</td>\n",
       "      <td>4.145098</td>\n",
       "      <td>9.191265</td>\n",
       "      <td>2.436402</td>\n",
       "      <td>2.483921</td>\n",
       "      <td>9.031859</td>\n",
       "      <td>11.636386</td>\n",
       "      <td>4.923222</td>\n",
       "      <td>0.841045</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.943877</td>\n",
       "      <td>5.310079</td>\n",
       "      <td>4.410969</td>\n",
       "      <td>5.326159</td>\n",
       "      <td>3.979592</td>\n",
       "      <td>3.928571</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>9.603542</td>\n",
       "      <td>5.882353</td>\n",
       "      <td>0.244541</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.797415</td>\n",
       "      <td>8.304757</td>\n",
       "      <td>4.225930</td>\n",
       "      <td>11.627438</td>\n",
       "      <td>2.097700</td>\n",
       "      <td>1.987549</td>\n",
       "      <td>8.965516</td>\n",
       "      <td>14.094723</td>\n",
       "      <td>5.517242</td>\n",
       "      <td>1.224114</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.630686</td>\n",
       "      <td>7.464411</td>\n",
       "      <td>4.145098</td>\n",
       "      <td>8.742359</td>\n",
       "      <td>2.436402</td>\n",
       "      <td>2.483921</td>\n",
       "      <td>9.031859</td>\n",
       "      <td>10.991098</td>\n",
       "      <td>4.923222</td>\n",
       "      <td>0.841045</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 470 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         v1        v2        v4         v5        v6        v7         v9  \\\n",
       "0  1.335739  8.727474  3.921026   7.915266  2.599278  3.176895   9.999999   \n",
       "1  1.630686  7.464411  4.145098   9.191265  2.436402  2.483921   9.031859   \n",
       "2  0.943877  5.310079  4.410969   5.326159  3.979592  3.928571  12.666667   \n",
       "3  0.797415  8.304757  4.225930  11.627438  2.097700  1.987549   8.965516   \n",
       "4  1.630686  7.464411  4.145098   8.742359  2.436402  2.483921   9.031859   \n",
       "\n",
       "         v14       v16       v18   ...    v129_0  v129_1  v129_11  v129_2  \\\n",
       "0  11.636387  8.571429  0.106720   ...         1       0        0       0   \n",
       "1  11.636386  4.923222  0.841045   ...         1       0        0       0   \n",
       "2   9.603542  5.882353  0.244541   ...         0       0        0       1   \n",
       "3  14.094723  5.517242  1.224114   ...         0       1        0       0   \n",
       "4  10.991098  4.923222  0.841045   ...         1       0        0       0   \n",
       "\n",
       "   v129_3  v129_4  v129_5  v129_6  v129_7  v129_8  \n",
       "0       0       0       0       0       0       0  \n",
       "1       0       0       0       0       0       0  \n",
       "2       0       0       0       0       0       0  \n",
       "3       0       0       0       0       0       0  \n",
       "4       0       0       0       0       0       0  \n",
       "\n",
       "[5 rows x 470 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnp.data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnp.target.head()\n",
    "#bnp['ID'][1:5]\n",
    "#bnp['target'][1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        v37       v39        v40        v42        v44        v45        v48\n",
      "0  0.454546  4.012088   7.711453  12.707581  10.498338   9.848672  12.171733\n",
      "1  0.741471  1.237184  14.305766  12.924965  10.795169   9.142231  12.538022\n",
      "2  0.259740  7.378964  13.077201  12.346939   8.897561   5.343819  12.711328\n",
      "3  0.433735  0.287322  11.523045  12.935823  12.708574   9.670823  12.194855\n",
      "4  0.741471  1.237184  10.138920  12.924965  10.795169   9.142231  12.538022\n",
      "5  0.741471  1.237184   7.903915  12.924965  10.795169   9.142231  12.538022\n",
      "6  0.549451  0.031587  14.787641  14.445526  11.765638   9.406689  13.256878\n",
      "7  0.741471  1.237184   3.034513  12.924965  10.795169   9.142231  12.538022\n",
      "8  0.975611  3.169000  12.199552  11.741573  10.173000   7.936837  12.940907\n",
      "9  0.793651  0.075258  10.803126  13.267328  10.295850  12.480398  13.982603\n"
     ]
    }
   ],
   "source": [
    "print bnp.data.iloc[0:10,17:24] \n",
    "#print bnp.data.iloc[0:5,45:52]\n",
    "#print bnp.data.iloc[0:5,101:108]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        v19        v20       v21           v23       v25       v26       v27\n",
      "0  0.148883  18.869283  7.730923 -1.716131e-08  0.139412  1.720818  3.393503\n",
      "1  0.222300  17.773592  6.763110  1.093088e+00  3.056144  1.876031  2.743454\n",
      "2  0.144258  17.952332  5.245035 -2.785053e-07  0.113997  2.244897  5.306122\n",
      "3  0.231630  18.376407  7.517125 -4.805344e-07  0.148843  1.308269  2.303640\n",
      "4  0.222300  17.773592  6.414567  1.093088e+00  1.698129  1.876031  2.743454\n",
      "5  0.222300  17.773592  7.351426  1.093088e+00  0.218458  1.876031  2.743454\n",
      "6  0.443661  17.226675  6.661479  7.813019e-07  0.180765  1.070040  1.566147\n",
      "7  0.222300  17.773592  7.806704  1.093088e+00  1.698129  1.876031  2.743454\n",
      "8  0.180616  17.754603  6.034953 -3.643173e-07  0.058906  1.647940  3.089888\n",
      "9  0.271822  18.410067  8.312447  3.955979e-08  0.509588  1.168523  1.410891\n"
     ]
    }
   ],
   "source": [
    "bnp.data = bnp.data.drop('v22', 1)\n",
    "#bnp.data = bnp.data.drop('v56', 1)\n",
    "#bnp.data = bnp.data.drop('v125', 1)\n",
    "\"\"\"\n",
    "##print bnp.data.iloc[0:10,17:24]\n",
    "##print bnp.data.iloc[0:5,45:52]\n",
    "##print bnp.data.iloc[0:5,101:108]\n",
    "\"\"\"\n",
    "print bnp.data.iloc[0:10,17:24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114321, 470)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnp.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1.Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: (114321, 470)(114321,)\n",
      "Training: (91456, 470)(91456,)\n",
      "Test:     (22865, 470)(22865,)\n"
     ]
    }
   ],
   "source": [
    "# 1. Split the data set into two parts: training set and test set(with random_state=0, \n",
    "#    and test_size=1.0/2).\n",
    "import numpy as np\n",
    "import sklearn.cross_validation as cv\n",
    "\n",
    "# Generate a random split into training & test sets\n",
    "x_train, x_test, y_train, y_test = \\\n",
    "        cv.train_test_split(bnp.data, bnp.target, test_size=0.2, random_state=0)\n",
    "\n",
    "# Testing    \n",
    "print \"Original: \" + str(bnp.data.shape) + str(bnp.target.shape)\n",
    "print \"Training: \" + str(x_train.shape) + str(y_train.shape)\n",
    "print \"Test:     \" + str(x_test.shape)  + str(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ML Methods "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- The training error is: 0.00765\n",
      "- The test     error is: 0.24645\n"
     ]
    }
   ],
   "source": [
    "# (1) Fit a random forest on the training set. Report the training error and test error.\n",
    "from sklearn import ensemble\n",
    "rf = ensemble.RandomForestClassifier()\n",
    "rf.fit(x_train, y_train) # fit \n",
    "print \"- The training error is: %.5f\" %(1-rf.score(x_train, y_train))\n",
    "print \"- The test     error is: %.5f\" %(1-rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-141-61ff64386823>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mgrid_para_forest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'criterion'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'gini'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'entropy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max_depth'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m31\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_estimators\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m110\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mgrid_search_forest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_para_forest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mgrid_search_forest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"best parameters: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_search_forest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m         \"\"\"\n\u001b[0;32m--> 804\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[1;32m    551\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m                                     error_score=self.error_score)\n\u001b[0;32m--> 553\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m                 for train, test in cv)\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    660\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateComputeBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[1;32m   1529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1531\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    288\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 290\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    660\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateComputeBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    348\u001b[0m                                            max_leaf_nodes)\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# (2) Use the function grid_search.GridSearchCV to find the best parameters. \n",
    "#     a. What's the best parameters? \n",
    "#     b. What's the best score? \n",
    "#     c. What's the training error and test error of the best model. \n",
    "#     The possible combination of the parameters may be: \n",
    "#     grid_para_forest = {'criterion': ['gini', 'entropy'], '\n",
    "#                          max_depth': range(1, 31), \"n_estimators\": range(10, 110, 10)}\n",
    "import sklearn.grid_search as gs\n",
    "\n",
    "grid_para_forest = [{'criterion': ['gini', 'entropy'], 'max_depth': range(1, 31), \\\n",
    "                     \"n_estimators\": range(10, 110, 10)}]\n",
    "grid_search_forest = gs.GridSearchCV(rf, grid_para_forest, scoring='accuracy', cv=5)\n",
    "grid_search_forest.fit(x_train, y_train)\n",
    "\n",
    "print \"best parameters: \", grid_search_forest.best_params_\n",
    "print \"best scores: \", grid_search_forest.best_score_\n",
    "print \"best model training error: \", (1-grid_search_forest.score(x_train, y_train))\n",
    "print \"best model test error:  \", (1-grid_search_forest.score(x_test, y_test))  \n",
    "\n",
    "# Newly added from below\n",
    "print \"\\n\\n\"\n",
    "rf_feature_importance = zip(x_train, rf.feature_importances_)\n",
    "\n",
    "dtype = [('feature', 'S20'), ('importance', 'float')] # S10: 10-character string\n",
    "rf_feature_importance = np.array(rf_feature_importance, dtype = dtype)\n",
    "rf_feature_sort = np.sort(rf_feature_importance, order='importance')[::-1]\n",
    "\n",
    "print \"Most important features are: \\n\", rf_feature_sort\n",
    "print \"Least important features are: \\n\", np.sort(rf_feature_importance, order='importance')[-50:] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (3) What's the first 5 important features?\n",
    "rf_feature_importance = zip(x_train, rf.feature_importances_)\n",
    "\n",
    "dtype = [('feature', 'S20'), ('importance', 'float')] # S10: 10-character string\n",
    "rf_feature_importance = np.array(rf_feature_importance, dtype = dtype)\n",
    "rf_feature_sort = np.sort(rf_feature_importance, order='importance')[::-1]\n",
    "\n",
    "print \"Most important features are: \\n\", rf_feature_sort\n",
    "print \"Least important features are: \\n\", np.sort(rf_feature_importance, order='importance')[-50:] \n",
    "#print \"Top 5 important features are: \\n\", rf_feature_sort[0:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Top 'least' important features...\n",
    "np.sort(rf_feature_importance, order='importance')[-50:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. XGBoost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1. Definition\n",
    "* <b>XGBoost (eXtreme Gradient Boosting)</b> is an advanced implementation of gradient boosting algorithm\n",
    "\n",
    "#### 4.2.2. Advantages\n",
    "* <b>Regularization</b>\n",
    "* <b>Parallel Processing</b>\n",
    "* <b>High Flexibility</b>\n",
    "* <b>Handling Missing Values</b>\n",
    "* <b>Tree Pruning</b>\n",
    "* <b>Built-in Cross-Validation</b>\n",
    "* <b>Continue on Existing Model</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3. XGBoost Complete guide to tune the parameters \n",
    "* http://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v9</th>\n",
       "      <th>v14</th>\n",
       "      <th>...</th>\n",
       "      <th>v129_0</th>\n",
       "      <th>v129_1</th>\n",
       "      <th>v129_11</th>\n",
       "      <th>v129_2</th>\n",
       "      <th>v129_3</th>\n",
       "      <th>v129_4</th>\n",
       "      <th>v129_5</th>\n",
       "      <th>v129_6</th>\n",
       "      <th>v129_7</th>\n",
       "      <th>v129_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.335739</td>\n",
       "      <td>8.727474</td>\n",
       "      <td>3.921026</td>\n",
       "      <td>7.915266</td>\n",
       "      <td>2.599278</td>\n",
       "      <td>3.176895</td>\n",
       "      <td>9.999999</td>\n",
       "      <td>11.636387</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.630686</td>\n",
       "      <td>7.464411</td>\n",
       "      <td>4.145098</td>\n",
       "      <td>9.191265</td>\n",
       "      <td>2.436402</td>\n",
       "      <td>2.483921</td>\n",
       "      <td>9.031859</td>\n",
       "      <td>11.636386</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.943877</td>\n",
       "      <td>5.310079</td>\n",
       "      <td>4.410969</td>\n",
       "      <td>5.326159</td>\n",
       "      <td>3.979592</td>\n",
       "      <td>3.928571</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>9.603542</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.797415</td>\n",
       "      <td>8.304757</td>\n",
       "      <td>4.225930</td>\n",
       "      <td>11.627438</td>\n",
       "      <td>2.097700</td>\n",
       "      <td>1.987549</td>\n",
       "      <td>8.965516</td>\n",
       "      <td>14.094723</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1.630686</td>\n",
       "      <td>7.464411</td>\n",
       "      <td>4.145098</td>\n",
       "      <td>8.742359</td>\n",
       "      <td>2.436402</td>\n",
       "      <td>2.483921</td>\n",
       "      <td>9.031859</td>\n",
       "      <td>10.991098</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 472 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  target        v1        v2        v4         v5        v6        v7  \\\n",
       "0   3       1  1.335739  8.727474  3.921026   7.915266  2.599278  3.176895   \n",
       "1   4       1  1.630686  7.464411  4.145098   9.191265  2.436402  2.483921   \n",
       "2   5       1  0.943877  5.310079  4.410969   5.326159  3.979592  3.928571   \n",
       "3   6       1  0.797415  8.304757  4.225930  11.627438  2.097700  1.987549   \n",
       "4   8       1  1.630686  7.464411  4.145098   8.742359  2.436402  2.483921   \n",
       "\n",
       "          v9        v14   ...    v129_0  v129_1  v129_11  v129_2  v129_3  \\\n",
       "0   9.999999  11.636387   ...         1       0        0       0       0   \n",
       "1   9.031859  11.636386   ...         1       0        0       0       0   \n",
       "2  12.666667   9.603542   ...         0       0        0       1       0   \n",
       "3   8.965516  14.094723   ...         0       1        0       0       0   \n",
       "4   9.031859  10.991098   ...         1       0        0       0       0   \n",
       "\n",
       "   v129_4  v129_5  v129_6  v129_7  v129_8  \n",
       "0       0       0       0       0       0  \n",
       "1       0       0       0       0       0  \n",
       "2       0       0       0       0       0  \n",
       "3       0       0       0       0       0  \n",
       "4       0       0       0       0       0  \n",
       "\n",
       "[5 rows x 472 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import libraries:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "\n",
    "#train = pd.read_csv('train_modified.csv')\n",
    "train = pd.read_csv('./data/BNP_hi_removed4.csv')\n",
    "target = 'target'\n",
    "IDcol = 'ID'\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <b>XGBoost modelfit function</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modelfit(alg, dtrain, predictors,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain[target].values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds, \\\n",
    "                          metrics=['logloss'], early_stopping_rounds=early_stopping_rounds, show_progress=False)\n",
    "                          #metrics=['auc'], early_stopping_rounds=early_stopping_rounds, show_progress=False)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg_fit = alg.fit(dtrain[predictors], dtrain['target'],eval_metric='logloss')\n",
    "    print alg_fit\n",
    "    \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print \"\\nModel Report\"\n",
    "    print \"Accuracy : %.4g\" % metrics.accuracy_score(dtrain['target'].values, dtrain_predictions)\n",
    "    print \"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain['target'], dtrain_predprob)\n",
    "    print \"LOGLOSS Score (Train): %f\" % metrics.log_loss(dtrain['target'], dtrain_predprob)\n",
    "                    \n",
    "    feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<b>Parameter settings Step 1</b>\n",
    "* Fix learning rate and number of estimators for tuning tree-based parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until cv error hasn't decreased in 50 rounds.\n",
      "Stopping. Best iteration: 47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
      "       min_child_weight=1, missing=None, n_estimators=48, nthread=4,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=27, silent=True, subsample=0.8)\n",
      "\n",
      "Model Report\n",
      "Accuracy : 0.8054\n",
      "AUC Score (Train): 0.843149\n",
      "LOGLOSS Score (Train): 0.421273\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtUAAAEtCAYAAADHmpyCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ntdRSj/T/AbEkkGxzxNMBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118121d10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Choose all predictors except target & IDcols\n",
    "predictors = [x for x in train.columns if x not in [target, IDcol]]\n",
    "\n",
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27\n",
    ")\n",
    "\n",
    "modelfit(xgb1, train[:10000], predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Parameter settings Step 2</b>\n",
    "* Tune max_depth and min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: -0.48577, std: 0.00777, params: {'max_depth': 3, 'min_child_weight': 1},\n",
       "  mean: -0.48552, std: 0.00801, params: {'max_depth': 3, 'min_child_weight': 3},\n",
       "  mean: -0.48573, std: 0.00791, params: {'max_depth': 3, 'min_child_weight': 5},\n",
       "  mean: -0.48665, std: 0.00822, params: {'max_depth': 5, 'min_child_weight': 1},\n",
       "  mean: -0.48648, std: 0.00914, params: {'max_depth': 5, 'min_child_weight': 3},\n",
       "  mean: -0.48517, std: 0.00836, params: {'max_depth': 5, 'min_child_weight': 5},\n",
       "  mean: -0.49115, std: 0.00978, params: {'max_depth': 7, 'min_child_weight': 1},\n",
       "  mean: -0.48942, std: 0.00960, params: {'max_depth': 7, 'min_child_weight': 3},\n",
       "  mean: -0.48726, std: 0.00891, params: {'max_depth': 7, 'min_child_weight': 5},\n",
       "  mean: -0.49433, std: 0.01051, params: {'max_depth': 9, 'min_child_weight': 1},\n",
       "  mean: -0.49368, std: 0.00907, params: {'max_depth': 9, 'min_child_weight': 3},\n",
       "  mean: -0.49087, std: 0.00874, params: {'max_depth': 9, 'min_child_weight': 5}],\n",
       " {'max_depth': 5, 'min_child_weight': 5},\n",
       " -0.48517245425147004)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test1 = {\n",
    " 'max_depth':range(3,10,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=47, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, scoring='log_loss',n_jobs=4,iid=False, cv=5)\n",
    " #param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5) \n",
    "\n",
    "#gsearch1.fit(train[predictors],train[target]) # origin\n",
    "gsearch1.fit(train[:10000][predictors],train[:10000][target])\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: -0.48488, std: 0.00870, params: {'max_depth': 4, 'min_child_weight': 4},\n",
       "  mean: -0.48533, std: 0.00756, params: {'max_depth': 4, 'min_child_weight': 5},\n",
       "  mean: -0.48471, std: 0.00772, params: {'max_depth': 4, 'min_child_weight': 6},\n",
       "  mean: -0.48547, std: 0.00779, params: {'max_depth': 5, 'min_child_weight': 4},\n",
       "  mean: -0.48517, std: 0.00836, params: {'max_depth': 5, 'min_child_weight': 5},\n",
       "  mean: -0.48494, std: 0.00719, params: {'max_depth': 5, 'min_child_weight': 6},\n",
       "  mean: -0.48691, std: 0.00826, params: {'max_depth': 6, 'min_child_weight': 4},\n",
       "  mean: -0.48670, std: 0.00733, params: {'max_depth': 6, 'min_child_weight': 5},\n",
       "  mean: -0.48607, std: 0.00764, params: {'max_depth': 6, 'min_child_weight': 6}],\n",
       " {'max_depth': 4, 'min_child_weight': 6},\n",
       " -0.48471168253236135)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test2 = {\n",
    " 'max_depth':[4,5,6],\n",
    " 'min_child_weight':[4,5,6]\n",
    "}\n",
    "gsearch2 = GridSearchCV(estimator = XGBClassifier( learning_rate=0.1, n_estimators=47, max_depth=5,\n",
    " min_child_weight=5, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test2, scoring='log_loss',n_jobs=4,iid=False, cv=5)\n",
    " #param_grid = param_test2, scoring='roc_auc',n_jobs=4,iid=False, cv=5) \n",
    "\n",
    "#gsearch2.fit(train[predictors],train[target])\n",
    "gsearch2.fit(train[:10000][predictors],train[:10000][target])\n",
    "gsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: -0.48828, std: 0.00779, params: {'max_depth': 2, 'min_child_weight': 6},\n",
       "  mean: -0.48832, std: 0.00765, params: {'max_depth': 2, 'min_child_weight': 7},\n",
       "  mean: -0.48825, std: 0.00751, params: {'max_depth': 2, 'min_child_weight': 8},\n",
       "  mean: -0.48580, std: 0.00774, params: {'max_depth': 3, 'min_child_weight': 6},\n",
       "  mean: -0.48542, std: 0.00804, params: {'max_depth': 3, 'min_child_weight': 7},\n",
       "  mean: -0.48540, std: 0.00832, params: {'max_depth': 3, 'min_child_weight': 8},\n",
       "  mean: -0.48471, std: 0.00772, params: {'max_depth': 4, 'min_child_weight': 6},\n",
       "  mean: -0.48475, std: 0.00775, params: {'max_depth': 4, 'min_child_weight': 7},\n",
       "  mean: -0.48433, std: 0.00781, params: {'max_depth': 4, 'min_child_weight': 8}],\n",
       " {'max_depth': 4, 'min_child_weight': 8},\n",
       " -0.48433362864381102)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test2b = {\n",
    " 'max_depth':[2,3,4],\n",
    " 'min_child_weight':[6,7,8]\n",
    "}\n",
    "gsearch2b = GridSearchCV(estimator = XGBClassifier( learning_rate=0.1, n_estimators=47, max_depth=5,\n",
    " min_child_weight=5, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test2b, scoring='log_loss',n_jobs=4,iid=False, cv=5)\n",
    "\n",
    "gsearch2b.fit(train[:10000][predictors],train[:10000][target])\n",
    "gsearch2b.grid_scores_, gsearch2b.best_params_, gsearch2b.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: -0.48433, std: 0.00781, params: {'min_child_weight': 8},\n",
       "  mean: -0.48456, std: 0.00838, params: {'min_child_weight': 9},\n",
       "  mean: -0.48468, std: 0.00768, params: {'min_child_weight': 10},\n",
       "  mean: -0.48406, std: 0.00794, params: {'min_child_weight': 11}],\n",
       " {'min_child_weight': 11},\n",
       " -0.48406042914413677)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test2c = {\n",
    " 'min_child_weight':[8,9,10,11]\n",
    "}\n",
    "gsearch2c = GridSearchCV(estimator = XGBClassifier( learning_rate=0.1, n_estimators=47, max_depth=4,\n",
    " min_child_weight=8, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test2c, scoring='log_loss',n_jobs=4,iid=False, cv=5)\n",
    "\n",
    "gsearch2c.fit(train[:10000][predictors],train[:10000][target])\n",
    "gsearch2c.grid_scores_, gsearch2c.best_params_, gsearch2c.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<b> Parameter settings Step 3</b>\n",
    "* Tune Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: -0.48406, std: 0.00794, params: {'gamma': 0.0},\n",
       "  mean: -0.48442, std: 0.00734, params: {'gamma': 0.1},\n",
       "  mean: -0.48442, std: 0.00734, params: {'gamma': 0.2},\n",
       "  mean: -0.48416, std: 0.00732, params: {'gamma': 0.3},\n",
       "  mean: -0.48439, std: 0.00768, params: {'gamma': 0.4}],\n",
       " {'gamma': 0.0},\n",
       " -0.48406042914413677)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gamma tunning\n",
    "param_test3 = {\n",
    " 'gamma':[i/10.0 for i in range(0,5)]\n",
    "}\n",
    "\n",
    "gsearch3 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=47, max_depth=4,\n",
    " min_child_weight=11, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test3, scoring='log_loss',n_jobs=4,iid=False, cv=5)\n",
    " #param_grid = param_test3, scoring='roc_auc',n_jobs=4,iid=False, cv=5) \n",
    "\n",
    "#gsearch3.fit(train[predictors],train[target])\n",
    "gsearch3.fit(train[:10000][predictors],train[:10000][target])\n",
    "gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until cv error hasn't decreased in 50 rounds.\n",
      "Stopping. Best iteration: 53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
      "       gamma=0.0, learning_rate=0.1, max_delta_step=0, max_depth=4,\n",
      "       min_child_weight=11, missing=None, n_estimators=54, nthread=4,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=27, silent=True, subsample=0.8)\n",
      "\n",
      "Model Report\n",
      "Accuracy : 0.79\n",
      "AUC Score (Train): 0.794669\n",
      "LOGLOSS Score (Train): 0.450588\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtQAAAEtCAYAAAAoWPe8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nalArFAqFQqFQKBQj8P+iugcmtdkPugAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1172e8990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# re-calibrate the number of boosting rounds for the updated parameters.\n",
    "xgb2 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=140,\n",
    " max_depth=4,\n",
    " min_child_weight=11,\n",
    " gamma=0.0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "\n",
    "modelfit(xgb2, train[:10000], predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<b> Parameter settings Step 4</b>\n",
    "* Tune subsample and colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_test4 = {\n",
    " 'subsample':[i/10.0 for i in range(6,10)],\n",
    " 'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "}\n",
    "gsearch4 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=47, max_depth=4,\n",
    " min_child_weight=6, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test4, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch4.fit(train[predictors],train[target])\n",
    "gsearch4.grid_scores_, gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_test5 = {\n",
    " 'subsample':[i/100.0 for i in range(75,90,5)],\n",
    " 'colsample_bytree':[i/100.0 for i in range(75,90,5)]\n",
    "}\n",
    "gsearch5 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=47, max_depth=4,\n",
    " min_child_weight=6, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test5, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch5.fit(train[predictors],train[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<b>Parameter settings Step 5</b>\n",
    "* Tuning Regularization Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_test6 = {\n",
    " 'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "}\n",
    "gsearch6 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=47, max_depth=4,\n",
    " min_child_weight=6, gamma=0.1, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test6, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch6.fit(train[predictors],train[target])\n",
    "gsearch6.grid_scores_, gsearch6.best_params_, gsearch6.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aram_test7 = {\n",
    " 'reg_alpha':[0, 0.001, 0.005, 0.01, 0.05]\n",
    "}\n",
    "gsearch7 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=47, max_depth=4,\n",
    " min_child_weight=6, gamma=0.1, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test7, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch7.fit(train[predictors],train[target])\n",
    "gsearch7.grid_scores_, gsearch7.best_params_, gsearch7.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb3 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=47,\n",
    " max_depth=4,\n",
    " min_child_weight=6,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " reg_alpha=0.005,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb3, train, predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<b>Parameter settings Step 6</b> \n",
    "* Reducing Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb4 = XGBClassifier(\n",
    " learning_rate =0.01,\n",
    " n_estimators=5000,\n",
    " max_depth=4,\n",
    " min_child_weight=6,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " reg_alpha=0.005,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb4, train, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 4.3. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- The training error is: 0.00000\n",
      "- The test     error is: 0.29950\n",
      "- Feature importances are: \n",
      "[  5.26758523e-03   6.44926392e-03   6.12024145e-03   4.57549583e-03\n",
      "   8.24158399e-03   7.73041403e-03   7.16138460e-03   3.10072513e-02\n",
      "   6.69773354e-03   7.25383438e-03   7.19771644e-03   3.81847353e-02\n",
      "   4.63912121e-03   6.96850441e-03   8.04178944e-03   6.86993071e-03\n",
      "   8.77777963e-03   5.08370392e-03   8.96294319e-03   3.19872213e-02\n",
      "   6.43606784e-03   8.35193337e-03   7.50954889e-03   3.57494502e-03\n",
      "   1.36791668e-01   5.69649447e-03   5.61436905e-03   6.47228886e-03\n",
      "   5.43614315e-03   5.76340579e-03   8.64946709e-03   6.61616127e-03\n",
      "   8.60968189e-03   7.07991152e-03   8.75246127e-03   5.04056774e-03\n",
      "   8.23902386e-03   6.18374064e-03   6.74286251e-03   5.89958155e-03\n",
      "   6.11926079e-03   7.31731976e-03   4.30142188e-03   6.08133250e-03\n",
      "   7.56497407e-03   7.93491578e-03   5.52013123e-03   5.68703902e-03\n",
      "   7.23300361e-03   6.41488247e-03   4.13604730e-03   3.15856720e-02\n",
      "   5.94003939e-03   4.82654130e-03   8.58826788e-03   7.20354482e-03\n",
      "   7.45814552e-03   6.05216815e-03   1.11027481e-02   7.74744656e-03\n",
      "   5.64741955e-03   5.44528400e-03   6.27904209e-03   0.00000000e+00\n",
      "   0.00000000e+00   5.61278151e-05   1.10314871e-03   1.30474814e-03\n",
      "   1.90265606e-03   4.42391490e-03   3.62943940e-03   7.81207289e-04\n",
      "   8.29647201e-05   4.00818847e-03   1.68712174e-03   1.14523717e-03\n",
      "   8.00551168e-04   2.08756366e-03   2.19008823e-03   8.51940051e-05\n",
      "   8.59099211e-05   4.73102482e-04   2.47848976e-04   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   6.71214912e-05   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   4.51027086e-05   0.00000000e+00   8.59099211e-05\n",
      "   0.00000000e+00   8.11205783e-04   6.37902836e-04   4.80412889e-04\n",
      "   0.00000000e+00   1.07296080e-03   3.74102206e-04   2.69524057e-03\n",
      "   2.68238491e-03   3.85983247e-03   3.15952355e-03   2.15220231e-03\n",
      "   3.40560498e-03   3.38455500e-03   3.29513000e-03   3.13961319e-03\n",
      "   3.16274070e-03   2.62060831e-03   3.04704540e-03   0.00000000e+00\n",
      "   5.03110757e-05   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   3.93648417e-04   5.55766502e-04   1.10581924e-05   2.70098191e-04\n",
      "   0.00000000e+00   1.20203956e-04   1.97133961e-04   0.00000000e+00\n",
      "   2.23359571e-04   2.08734583e-04   0.00000000e+00   1.72441144e-04\n",
      "   6.93732920e-04   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   9.19308245e-04   0.00000000e+00   0.00000000e+00   1.84555345e-04\n",
      "   0.00000000e+00   5.11516005e-05   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   1.22230560e-04\n",
      "   2.81142545e-05   4.88399706e-04   3.36350454e-04   1.00548095e-03\n",
      "   9.76622399e-05   2.69944624e-05   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   5.47702152e-04   2.38353809e-03   5.42955319e-04\n",
      "   8.54247259e-05   9.30593458e-04   8.07901249e-05   5.52410878e-05\n",
      "   5.84187463e-05   1.47124501e-04   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   1.59984411e-04   1.12372443e-04\n",
      "   0.00000000e+00   0.00000000e+00   5.50813114e-05   3.06316201e-04\n",
      "   1.16375144e-03   2.23793138e-04   1.98302912e-04   2.83606031e-05\n",
      "   1.12923818e-04   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   2.08084966e-03   0.00000000e+00   0.00000000e+00\n",
      "   2.45125794e-04   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   5.20677802e-05   9.46438763e-04   0.00000000e+00   6.66668811e-04\n",
      "   9.49943928e-04   3.65730264e-04   0.00000000e+00   0.00000000e+00\n",
      "   2.02132436e-05   1.00762329e-04   1.02345006e-03   1.04774553e-03\n",
      "   0.00000000e+00   5.46818438e-04   3.40472152e-04   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   6.99359817e-04\n",
      "   8.34007864e-04   6.04544858e-05   0.00000000e+00   0.00000000e+00\n",
      "   6.89892983e-04   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   3.09313584e-04   0.00000000e+00   1.04218547e-03\n",
      "   0.00000000e+00   3.93850924e-04   0.00000000e+00   7.21717522e-04\n",
      "   1.83569385e-04   0.00000000e+00   0.00000000e+00   4.64673412e-04\n",
      "   0.00000000e+00   1.45788849e-04   2.02745916e-03   1.93175038e-03\n",
      "   6.09778841e-04   8.36001317e-05   8.81230756e-05   0.00000000e+00\n",
      "   0.00000000e+00   7.37621724e-03   6.01302632e-03   1.93786427e-02\n",
      "   0.00000000e+00   3.10582612e-03   1.87316216e-03   0.00000000e+00\n",
      "   1.91280236e-03   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   4.88676142e-05   2.21103726e-03   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   2.49524967e-03   1.14212587e-03\n",
      "   3.56865952e-04   1.39422609e-04   3.17477677e-05   6.88227604e-05\n",
      "   0.00000000e+00   0.00000000e+00   4.20805593e-05   7.41915785e-04\n",
      "   1.81494787e-04   5.20666188e-05   2.62844049e-03   3.00684724e-05\n",
      "   1.68036219e-03   6.66257282e-05   5.37188995e-04   1.28432614e-03\n",
      "   7.58945357e-04   1.80817848e-03   1.09374313e-04   0.00000000e+00\n",
      "   4.01615655e-04   1.29566138e-03   0.00000000e+00   3.58015506e-04\n",
      "   0.00000000e+00   7.86255367e-04   0.00000000e+00   1.06957852e-04\n",
      "   3.41080463e-04   6.34987880e-04   0.00000000e+00   3.02134494e-03\n",
      "   2.04342298e-03   2.28449409e-03   1.32317868e-04   4.59404486e-04\n",
      "   1.84332818e-03   2.37800329e-03   2.04609845e-03   3.13620273e-03\n",
      "   2.36240588e-03   2.00954384e-03   2.77465130e-03   7.71132182e-04\n",
      "   1.73574796e-04   1.19449290e-02   8.19610832e-03   5.19637600e-04\n",
      "   2.02228794e-03   6.88201349e-04   4.26993813e-04   1.51369489e-03\n",
      "   1.04048674e-03   2.46388040e-03   9.25075320e-04   1.59028143e-03\n",
      "   1.75623872e-03   1.18660778e-03   1.00650505e-03   1.51668403e-03\n",
      "   4.40668818e-04   1.11368156e-03   1.51700039e-03   1.88395128e-03\n",
      "   8.64436617e-04   1.10089866e-03   4.62979876e-04   1.48706828e-03\n",
      "   1.44689897e-03   1.19736641e-03   4.89298627e-04   0.00000000e+00\n",
      "   7.22359655e-04   1.72974332e-03   2.05523255e-04   1.03232480e-03\n",
      "   1.68327993e-03   1.07594546e-03   5.28096590e-04   5.61561512e-04\n",
      "   7.80033314e-04   0.00000000e+00   1.15121869e-03   5.84321721e-04\n",
      "   1.48957346e-04   3.57978265e-04   1.60439997e-04   2.14890638e-03\n",
      "   5.18679890e-05   9.44313417e-04   3.63364880e-04   2.91855158e-04\n",
      "   6.88616478e-04   1.47765064e-04   1.49102392e-04   1.05687448e-03\n",
      "   5.19109756e-04   2.96707724e-04   5.11599349e-04   4.31933329e-04\n",
      "   3.66503939e-04   1.29823218e-03   9.14871512e-04   8.10320997e-04\n",
      "   1.14094521e-03   1.28168957e-04   1.54890907e-03   7.05898019e-04\n",
      "   1.34532626e-04   1.36902268e-03   8.08439394e-04   3.86014661e-04\n",
      "   1.34317484e-03   7.20991440e-04   4.79964645e-04   9.74452854e-04\n",
      "   9.52600714e-05   2.01148029e-03   7.26998217e-04   8.90925902e-04\n",
      "   8.20989267e-04   7.07149183e-04   2.11155607e-03   3.24776466e-04\n",
      "   1.64869495e-03   6.34083164e-04   4.56726563e-04   9.81176847e-04\n",
      "   6.03685426e-04   8.25299526e-04   5.08483939e-05   9.79202480e-04\n",
      "   9.37708387e-04   1.75644326e-03   3.30045515e-04   2.85834835e-04\n",
      "   2.28099836e-04   1.01923841e-03   8.35967784e-04   4.40064815e-04\n",
      "   4.11627383e-04   9.93861310e-04   7.19104829e-04   2.09066725e-03\n",
      "   8.17273840e-04   7.84966564e-04   2.60817135e-03   7.92600442e-04\n",
      "   1.08043476e-03   6.02950683e-04   6.15587090e-04   7.41780440e-04\n",
      "   2.98452294e-04   4.07056448e-04   8.06531182e-04   9.49107582e-04\n",
      "   1.63489981e-03   1.41260827e-03   1.69478951e-03   0.00000000e+00\n",
      "   1.00587362e-03   1.06820577e-03   5.04559706e-04   7.82614047e-04\n",
      "   1.54783623e-03   9.84066759e-04   9.15414043e-04   1.94866961e-03\n",
      "   7.71208560e-04   3.65031864e-04   1.35284315e-03   6.56705825e-04\n",
      "   8.92936513e-04   7.79523314e-04   1.48741081e-03   3.30004512e-04\n",
      "   1.07581989e-03   1.36685244e-03   5.64284169e-04   9.74398404e-04\n",
      "   1.88052898e-03   1.94677444e-03   5.35130051e-04   1.12074980e-03\n",
      "   3.58877377e-04   9.97424322e-04   1.44298096e-03   9.30941377e-04\n",
      "   1.07983574e-03   8.57947713e-04   1.37893459e-03   2.30840134e-03\n",
      "   9.22578667e-04   7.72361603e-04   8.43164876e-04   1.15370331e-03\n",
      "   9.60551255e-04   4.63100254e-04   0.00000000e+00   3.97036580e-04\n",
      "   7.34811153e-05   1.35867126e-04   4.85124800e-05   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "# (1) Fit a decision tree model on the training set with the default setting.\n",
    "from sklearn import tree\n",
    "import sklearn.grid_search as gs\n",
    "tree_model = tree.DecisionTreeClassifier()\n",
    "tree_model.fit(x_train, y_train)\n",
    "\n",
    "## Test\n",
    "print \"- The training error is: %.5f\" %(1-tree_model.score(x_train, y_train))\n",
    "print \"- The test     error is: %.5f\" %(1-tree_model.score(x_test, y_test))\n",
    "print \"- Feature importances are: \\n\", tree_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (2) Set the depth of the tree from 1 to 30. Look the varies of the training error and test error.\n",
    "depth = range(1,30)\n",
    "train_error = []\n",
    "test_error = []\n",
    "for i in depth:\n",
    "    tree_model.set_params(max_depth = i, min_samples_leaf=1)\n",
    "    tree_model.fit(x_train, y_train)\n",
    "    train_error.append(1 - tree_model.score(x_train, y_train))\n",
    "    test_error.append(1 - tree_model.score(x_test, y_test))\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "%pylab inline\n",
    "import matplotlib.pyplot as pl\n",
    "pl.plot(depth, train_error, c = 'red', label = 'training error')\n",
    "pl.plot(depth, test_error, c = 'blue', label = 'test error')\n",
    "pl.ylim(0, 0.35)\n",
    "pl.legend()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (3) Use the function grid_search.GridSearchCV to find the best parameters. \n",
    "#     a.What's the best parameters? \n",
    "#     b.What's the best score? \n",
    "#     c.What's the training error and test error of the best model. \n",
    "#     The possible combination of the parameters may be: \n",
    "grid_para_tree = {'criterion': ['gini', 'entropy'], 'max_depth': range(1, 11)}\n",
    "#grid_search_tree = gs.GridSearchCV(tree_model, grid_para_tree, cv=5, scoring='accuracy')\n",
    "grid_search_tree = gs.GridSearchCV(tree_model, grid_para_tree, cv=5, scoring='logloss')\n",
    "grid_search_tree.fit(x_train, y_train)\n",
    "print \"best parameters: \", grid_search_tree.best_params_\n",
    "print \"best scores: \", grid_search_tree.best_score_\n",
    "print \"best model training error: \", (1-grid_search_tree.score(x_train, y_train)) # overall accuracy on the training set:\n",
    "print \"best model test error:  \", (1-grid_search_tree.score(x_test, y_test))   # overall accuracy on the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top important features are: \n",
      "[('v50', 0.14057278011124794) ('v21', 0.0276056988711409)\n",
      " ('v66_C', 0.02596362563216391) ('v14', 0.022230693081453118)\n",
      " ('v12', 0.021499394892526922) ('v34', 0.02065936258279592)\n",
      " ('v40', 0.018446462293741736) ('v114', 0.017249637890962698)\n",
      " ('v110_A', 0.014218364452579329) ('v10', 0.01411988948921134)\n",
      " ('v66_B', 0.012613352070140872) ('v120', 0.007946379125903378)\n",
      " ('v110_B', 0.007868753523342795) ('v99', 0.007735050326966314)\n",
      " ('v39', 0.007678787548993244) ('v82', 0.007402035435686816)\n",
      " ('v85', 0.007156321053584827) ('v102', 0.007035327548171138)\n",
      " ('v70', 0.006978212538767433) ('v35', 0.006752662680096564)\n",
      " ('v124', 0.006705004538550452) ('v28', 0.006666906058355843)\n",
      " ('v6', 0.006615352558166093) ('v1', 0.00655655669345863)\n",
      " ('v88', 0.006551532907318146) ('v44', 0.006507646699740642)\n",
      " ('v57', 0.006481451893190328) ('v16', 0.0064225172458518675)\n",
      " ('v36', 0.0062418457208903155) ('v122', 0.006222718382557189)\n",
      " ('v117', 0.005923910532968088) ('v100', 0.005916954524476314)\n",
      " ('v119', 0.0058877440665214) ('v103', 0.005782432643186825)\n",
      " ('v18', 0.005775512789759797) ('v127', 0.0056548781128158915)\n",
      " ('v78', 0.005645541381203125) ('v68', 0.0055902635834024095)\n",
      " ('v87', 0.005589748703255688) ('v13', 0.005503741462001249)\n",
      " ('v98', 0.005468790228985394) ('v54', 0.005461175086507087)\n",
      " ('v27', 0.005426775724479488) ('v80', 0.0054162595979869235)\n",
      " ('v97', 0.005394191019538413) ('v7', 0.005391090816709855)\n",
      " ('v69', 0.005307446985537017) ('v90', 0.005292677994996449)\n",
      " ('v89', 0.00511461028740688) ('v9', 0.005001072549773094)\n",
      " ('v37', 0.004877108712707145) ('v20', 0.004778168742228782)\n",
      " ('v123', 0.004690753458857137) ('v126', 0.0045932584429940375)\n",
      " ('v115', 0.004589477695647284) ('v2', 0.004586323808237651)\n",
      " ('v111', 0.004569103772490096) ('v118', 0.0045145022118761)\n",
      " ('v131', 0.004478624161690178) ('v55', 0.004456191789820079)\n",
      " ('v23', 0.0044126494814948555) ('v19', 0.004388615285485699)\n",
      " ('v104', 0.004329682169739356) ('v58', 0.0043190305582738)\n",
      " ('v11', 0.004278456948920083) ('v65', 0.0042012448976643645)\n",
      " ('v92', 0.004180042829578376) ('v109', 0.004149635718817146)\n",
      " ('v60', 0.004109484266409002) ('v84', 0.004060734366658236)\n",
      " ('v81', 0.004052943830496709) ('v61', 0.0040520171828569325)\n",
      " ('v86', 0.004050941469140749) ('v108', 0.003990015381339952)\n",
      " ('v32', 0.003955811846145219) ('v101', 0.003945562186255555)\n",
      " ('v25', 0.003859039078859336) ('v45', 0.003796891004986156)\n",
      " ('v121', 0.003792122743217639) ('v73', 0.0037739050817663924)\n",
      " ('v130', 0.0037361030677097143) ('v49', 0.0037262014589628735)\n",
      " ('v43', 0.0037149683221650446) ('v26', 0.003680697272054613)\n",
      " ('v4', 0.003652734595193168) ('v77', 0.0036301053159869113)\n",
      " ('v53', 0.0034892023810072425) ('v24_E', 0.0033871824737537653)\n",
      " ('v94', 0.0033695369863644565) ('v33', 0.003283692446078393)\n",
      " ('v105', 0.0032829870737471427) ('v42', 0.0032607586597150676)\n",
      " ('v5', 0.003246971811514642) ('v15', 0.003227218107410642)\n",
      " ('v59', 0.003172114382616971) ('v24_D', 0.003160101705143208)\n",
      " ('v83', 0.0031450447750981914) ('v51', 0.003109024314933253)\n",
      " ('v93', 0.003096723389192987) ('v116', 0.003081471758391277)\n",
      " ('v8', 0.0029910395777558185) ('v63', 0.002982423253865174)\n",
      " ('v41', 0.00288717167020493) ('v67', 0.0028640837561417906)\n",
      " ('v96', 0.0028490638469155748) ('v31_A', 0.002785853209420688)\n",
      " ('v128', 0.002785313500966501) ('v48', 0.0027787758076447985)\n",
      " ('v106', 0.0027740872602618756) ('v56_BW', 0.002697900130285388)\n",
      " ('v17', 0.002626869795199413) ('v52_G', 0.002611434932298957)\n",
      " ('v52_D', 0.002590909269864851) ('v52_I', 0.00250493705010233)\n",
      " ('v29', 0.0024782069244396513) ('v52_F', 0.002464563596688499)\n",
      " ('v56_CY', 0.002452499213399697) ('v64', 0.002447792221450056)\n",
      " ('v47_C', 0.002401103055584713) ('v46', 0.0022363863762994854)\n",
      " ('v76', 0.0022013987384842445) ('v112_F', 0.0021760322113037306)\n",
      " ('v79_E', 0.002074625283812738) ('v30_C', 0.0020736404476236147)\n",
      " ('v52_C', 0.002023706349888908) ('v52_L', 0.002014516439805787)\n",
      " ('v107_C', 0.0019971601794812398) ('v72_1', 0.0019260360534891878)\n",
      " ('v52_J', 0.0018771184908828252) ('v75_D', 0.0017162193582044758)\n",
      " ('v112_A', 0.0016954523363542594) ('v66_A', 0.0016570433352735825)\n",
      " ('v95', 0.0016325455549078903) ('v24_C', 0.0016150583032418695)\n",
      " ('v52_H', 0.001611238883451781) ('v112_N', 0.00160904919062492)\n",
      " ('v91_C', 0.0015898912440196196) ('v52_B', 0.0015751760632090235)\n",
      " ('v91_B', 0.0015737947639193352) ('v52_A', 0.001559252561526826)\n",
      " ('v52_E', 0.0015205608865474086) ('v112_P', 0.0014594007715954343)\n",
      " ('v71_F', 0.0014271505662627971) ('v125_AP', 0.0013905452198913087)\n",
      " ('v125_CG', 0.0013790633980170746) ('v112_H', 0.001347496319636199)\n",
      " ('v113_G', 0.0013365129001086553) ('v71_C', 0.0013086495898531943)\n",
      " ('v125_K', 0.0013016837865918408) ('v125_BM', 0.0012897235522610594)\n",
      " ('v125_BY', 0.0012644091953432598) ('v71_B', 0.0012634480401559592)\n",
      " ('v113_AF', 0.0012581694496957582) ('v79_C', 0.0012490755022521178)\n",
      " ('v30_D', 0.001238898394023093) ('v91_A', 0.0012323045821080627)\n",
      " ('v107_B', 0.0012164458386735946) ('v24_A', 0.0011958006250108446)\n",
      " ('v125_BW', 0.0011661459962770866) ('v52_K', 0.0011651474545185793)\n",
      " ('v125_AK', 0.0011637880429488066) ('v112_O', 0.00115379323945012)\n",
      " ('v113_AG', 0.001138783183883261) ('v24_B', 0.0011285583603124632)\n",
      " ('v72_2', 0.0011237063478537067) ('v62_2', 0.0011114346542117014)\n",
      " ('v91_G', 0.001102692093737777) ('v125_E', 0.001089304775265819)\n",
      " ('v107_E', 0.0010712640994435384) ('v125_BJ', 0.0010662244374499744)\n",
      " ('v125_BL', 0.0010636074049336535) ('v75_B', 0.00106262119128099)\n",
      " ('v125_H', 0.0010538350344765797) ('v107_A', 0.0010528084491351003)\n",
      " ('v125_B', 0.0010516848047380744) ('v125_L', 0.0010387619981084553)\n",
      " ('v107_D', 0.0010260301820587626) ('v125_AC', 0.0009873881136103705)\n",
      " ('v125_V', 0.000980755290889433) ('v113_V', 0.0009736950610136194)\n",
      " ('v113_P', 0.0009735044297308775) ('v62_1', 0.000964962422971803)\n",
      " ('v56_P', 0.0009469330117820667) ('v113_AC', 0.0009457001937057738)\n",
      " ('v125_AR', 0.000938862449319565) ('v112_I', 0.0009240178538865276)\n",
      " ('v56_DY', 0.0009199530772699178) ('v79_M', 0.0009080499265625601)\n",
      " ('v125_CJ', 0.0008951590729266651) ('v113_AB', 0.0008855998776533319)\n",
      " ('v125_N', 0.000876881172503444) ('v125_T', 0.0008717267158952593)\n",
      " ('v113_W', 0.0008666957424381877) ('v125_P', 0.0008612940001000957)\n",
      " ('v125_A', 0.0008489264644274094) ('v112_E', 0.0008476693328578366)\n",
      " ('v72_0', 0.0008369132365251357) ('v125_AI', 0.0008354762677432767)\n",
      " ('v125_J', 0.0008170308968621939) ('v113_I', 0.0008115874155964353)\n",
      " ('v125_G', 0.0007982388810339868) ('v125_D', 0.0007963882952382335)\n",
      " ('v113_B', 0.0007911476239430042) ('v125_BP', 0.0007851643146683394)\n",
      " ('v30_G', 0.0007846249542283614) ('v47_I', 0.0007843559321581934)\n",
      " ('v112_K', 0.0007835231916845445) ('v125_Z', 0.000775504793428014)\n",
      " ('v125_AY', 0.0007711354236681638) ('v125_CD', 0.000766247917595965)\n",
      " ('v125_AZ', 0.0007625651782450346) ('v125_AA', 0.0007609104411389426)\n",
      " ('v125_AT', 0.0007594723347298112) ('v112_L', 0.0007579052313938098)\n",
      " ('v125_AL', 0.000752963767529758) ('v125_BD', 0.0007500914745940454)\n",
      " ('v56_BZ', 0.0007341403702255229) ('v113_AE', 0.0007336254314462978)\n",
      " ('v112_C', 0.0007315568328037231) ('v112_T', 0.0007248440932249702)\n",
      " ('v56_CN', 0.0007157494181298269) ('v56_DF', 0.0007148211077513335)\n",
      " ('v125_BX', 0.0007138215670722241) ('v91_F', 0.0007100815055512396)\n",
      " ('v112_D', 0.0007085201138558912) ('v125_CH', 0.000684274909450126)\n",
      " ('v56_DO', 0.000675677265851501) ('v125_CC', 0.0006684739748595893)\n",
      " ('v112_J', 0.0006673954494439189) ('v107_F', 0.0006571629624815338)\n",
      " ('v56_U', 0.0006544447155913747) ('v125_S', 0.0006471215811692469)\n",
      " ('v47_E', 0.0006444032093300939) ('v112_U', 0.0006426122668104031)\n",
      " ('v125_BU', 0.0006396879544594376) ('v56_AW', 0.0006393257345709384)\n",
      " ('v113_S', 0.0006337626360271073) ('v125_BK', 0.0006262282394369694)\n",
      " ('v112_V', 0.0006121184212479447) ('v125_BO', 0.0006083648285275347)\n",
      " ('v125_Q', 0.0006031504149560871) ('v56_BV', 0.0005987073596085498)\n",
      " ('v125_R', 0.0005979372891933137) ('v125_AF', 0.0005967490707854094)\n",
      " ('v125_AN', 0.0005921777594050441) ('v72_3', 0.0005915600357568925)\n",
      " ('v47_J', 0.0005904384630564839) ('v56_DI', 0.0005846685543750239)\n",
      " ('v113_AJ', 0.0005818732484957238) ('v125_BV', 0.0005645524961731641)\n",
      " ('v56_DR', 0.0005614885753689242) ('v125_CE', 0.0005525633544500873)\n",
      " ('v113_Y', 0.0005509128493402068) ('v30_E', 0.0005428115793931708)\n",
      " ('v125_AM', 0.0005403525835694748) ('v125_AS', 0.0005396573545512994)\n",
      " ('v62_3', 0.0005361892077481659) ('v125_AH', 0.0005317434925451547)\n",
      " ('v129_1', 0.0005196264859608189) ('v125_Y', 0.0005077345694462532)\n",
      " ('v56_BX', 0.0005013286448233738) ('v129_0', 0.0005012197833434263)\n",
      " ('v112_Q', 0.0004961765202183715) ('v79_B', 0.0004930068824709164)\n",
      " ('v112_G', 0.0004901267695743771) ('v125_BH', 0.00048491864072591724)\n",
      " ('v125_CF', 0.00047797210314873414) ('v125_M', 0.0004709057180693711)\n",
      " ('v79_D', 0.00046834097939294644) ('v112_R', 0.00046182608482863986)\n",
      " ('v125_BE', 0.00045285849941267283) ('v56_DP', 0.0004521880565691925)\n",
      " ('v56_DJ', 0.00044360444493014937) ('v56_R', 0.00043488426113668467)\n",
      " ('v125_AU', 0.0004336779020282589) ('v30_A', 0.00042804160872893005)\n",
      " ('v38_0', 0.00042735652264294714) ('v125_CK', 0.0004165274919275068)\n",
      " ('v56_AG', 0.00041287657316039573) ('v125_BF', 0.0004122022857930341)\n",
      " ('v113_AD', 0.0004115393448424125) ('v47_G', 0.00040968733562931915)\n",
      " ('v56_BL', 0.00039132894630057634) ('v113_AI', 0.0003841941253227995)\n",
      " ('v125_BN', 0.00037904744549378306) ('v125_X', 0.00037806908160645274)\n",
      " ('v125_AQ', 0.0003754072289482497) ('v125_AW', 0.0003750098385826627)\n",
      " ('v113_M', 0.0003725246083563161) ('v56_BJ', 0.0003711271623084278)\n",
      " ('v125_AO', 0.0003674389750584303) ('v125_C', 0.0003650761582580709)\n",
      " ('v112_M', 0.0003595619863644906) ('v125_BQ', 0.0003581662084026207)\n",
      " ('v125_CL', 0.0003508667638283471) ('v125_W', 0.000348321826045742)\n",
      " ('v113_C', 0.0003469701930336764) ('v91_E', 0.0003459445506002024)\n",
      " ('v56_G', 0.0003459219797903928) ('v79_I', 0.0003403231440873174)\n",
      " ('v56_AS', 0.0003343318188394359) ('v125_BI', 0.00033388262405681596)\n",
      " ('v56_N', 0.0003301707509321602) ('v79_P', 0.0003242380817951177)\n",
      " ('v125_CA', 0.00032416716337296673) ('v113_A', 0.0003183892659021244)\n",
      " ('v125_AG', 0.00031313182011117387) ('v113_X', 0.00030741435861918935)\n",
      " ('v112_S', 0.000307252826198232) ('v125_U', 0.0003030439523461256)\n",
      " ('v107_G', 0.0003017057136159903) ('v125_I', 0.00029890137003564114)\n",
      " ('v125_F', 0.0002882873974093546) ('v113_N', 0.00028723769901109686)\n",
      " ('v125_AE', 0.00028596489032132555) ('v56_DX', 0.0002845468134455143)\n",
      " ('v56_AN', 0.00028060940813443046) ('v125_O', 0.00027211714089926046)\n",
      " ('v79_Q', 0.0002720737388431191) ('v125_BS', 0.00027148491827048006)\n",
      " ('v125_AV', 0.00027005117607213386) ('v74_B', 0.0002635734766047766)\n",
      " ('v30_F', 0.00026310953871917076) ('v125_BG', 0.0002539408943894843)\n",
      " ('v113_L', 0.00024801560254079046) ('v56_CH', 0.0002471388283528215)\n",
      " ('v125_CB', 0.00023725907925418083) ('v113_U', 0.0002324360057342171)\n",
      " ('v56_DH', 0.00023162220431716194) ('v125_AD', 0.0002267211436122434)\n",
      " ('v112_B', 0.00022486068059685867) ('v56_AR', 0.0002183592832087654)\n",
      " ('v113_AH', 0.00021746938386726656) ('v125_BC', 0.00021670460027997128)\n",
      " ('v113_F', 0.00020125793683237807) ('v79_K', 0.00019460285247782416)\n",
      " ('v56_AO', 0.00019300843582519938) ('v47_F', 0.00018329653192968772)\n",
      " ('v125_BR', 0.000182403223021984) ('v56_AF', 0.00018136144748190158)\n",
      " ('v72_5', 0.00017978694483378999) ('v38_1', 0.00017888054207383997)\n",
      " ('v129_2', 0.00017023395940379956) ('v79_F', 0.00017010581578522478)\n",
      " ('v113_E', 0.00016876292805713698) ('v62_5', 0.0001687219418437124)\n",
      " ('v74_C', 0.0001589730773636559) ('v79_H', 0.0001579395765444527)\n",
      " ('v38_3', 0.0001550789849690711) ('v113_D', 0.00015455723391697365)\n",
      " ('v56_DS', 0.00015383909022811265) ('v56_DA', 0.0001525068492226244)\n",
      " ('v125_BT', 0.00014654710667186258) ('v125_BA', 0.00014556776633112227)\n",
      " ('v62_4', 0.00014206063801172145) ('v125_AB', 0.00013896011864699401)\n",
      " ('v31_C', 0.000137017577081107) ('v113_J', 0.00013111403560285285)\n",
      " ('v56_CA', 0.00012666790084335457) ('v47_B', 0.00011760706856479555)\n",
      " ('v113_Q', 0.00011706232698673417) ('v125_CI', 0.00010991201592491891)\n",
      " ('v38_5', 0.00010875387773739026) ('v56_AI', 0.00010873705815836412)\n",
      " ('v113_T', 0.00010826542659313722) ('v113_Z', 0.00010642225140088942)\n",
      " ('v72_6', 0.00010637982503874135) ('v113_O', 0.0001011368413904549)\n",
      " ('v56_CI', 0.00010053832552248143) ('v56_BG', 0.00010002234419194881)\n",
      " ('v79_A', 8.719300359706807e-05) ('v56_AK', 8.696652826304977e-05)\n",
      " ('v72_4', 7.198845422984585e-05) ('v113_R', 7.066694085355262e-05)\n",
      " ('v56_CC', 6.985616875486868e-05) ('v56_Y', 6.9227087174567e-05)\n",
      " ('v56_BM', 6.872678123260719e-05) ('v56_CL', 6.854657340814236e-05)\n",
      " ('v125_BB', 6.623953999111546e-05) ('v56_BA', 6.614720699594743e-05)\n",
      " ('v113_H', 6.53835341555271e-05) ('v56_C', 6.499213611546368e-05)\n",
      " ('v56_DK', 6.47072382909596e-05) ('v125_AX', 6.393678510103303e-05)\n",
      " ('v56_V', 6.228071685504864e-05) ('v56_CM', 6.228071685504864e-05)\n",
      " ('v56_CF', 6.177021917590885e-05) ('v56_CS', 5.978948818084667e-05)\n",
      " ('v56_BK', 5.978948818084667e-05) ('v79_G', 5.97827378999295e-05)\n",
      " ('v79_O', 4.98245734840389e-05) ('v56_AA', 3.7368430113029176e-05)\n",
      " ('v129_4', 3.5905040488319426e-05) ('v56_CQ', 3.569636379730199e-05)\n",
      " ('v56_BI', 3.568052573332504e-05) ('v91_D', 3.422793173752164e-05)\n",
      " ('v56_CP', 3.38321630014965e-05) ('v56_BN', 3.375466898763775e-05)\n",
      " ('v56_AZ', 3.307599281860167e-05) ('v56_Z', 3.2678465200058164e-05)\n",
      " ('v56_DM', 2.5397856171653737e-05) ('v56_DN', 2.4547716692136265e-05)\n",
      " ('v56_AH', 1.3738982797634871e-05) ('v56_AL', 8.032692815664996e-06)\n",
      " ('v56_DL', 5.743966626648846e-06) ('v79_R', 0.0) ('v79_N', 0.0)\n",
      " ('v79_L', 0.0) ('v79_J', 0.0) ('v75_C', 0.0) ('v75_A', 0.0) ('v74_A', 0.0)\n",
      " ('v72_9', 0.0) ('v72_8', 0.0) ('v72_7', 0.0) ('v72_12', 0.0)\n",
      " ('v72_11', 0.0) ('v72_10', 0.0) ('v71_L', 0.0) ('v71_K', 0.0)\n",
      " ('v71_I', 0.0) ('v71_G', 0.0) ('v71_D', 0.0) ('v71_A', 0.0) ('v62_7', 0.0)\n",
      " ('v62_6', 0.0) ('v62_0', 0.0) ('v56_X', 0.0) ('v56_W', 0.0) ('v56_T', 0.0)\n",
      " ('v56_Q', 0.0) ('v56_O', 0.0) ('v56_M', 0.0) ('v56_L', 0.0) ('v56_I', 0.0)\n",
      " ('v56_H', 0.0) ('v56_F', 0.0) ('v56_E', 0.0) ('v56_DZ', 0.0)\n",
      " ('v56_DW', 0.0) ('v56_DV', 0.0) ('v56_DU', 0.0) ('v56_DT', 0.0)\n",
      " ('v56_DQ', 0.0) ('v56_DG', 0.0) ('v56_DE', 0.0) ('v56_DD', 0.0)\n",
      " ('v56_DC', 0.0) ('v56_DB', 0.0) ('v56_D', 0.0) ('v56_CZ', 0.0)\n",
      " ('v56_CX', 0.0) ('v56_CW', 0.0) ('v56_CV', 0.0) ('v56_CT', 0.0)\n",
      " ('v56_CO', 0.0) ('v56_CK', 0.0) ('v56_CJ', 0.0) ('v56_CG', 0.0)\n",
      " ('v56_CE', 0.0) ('v56_CD', 0.0) ('v56_CB', 0.0) ('v56_BY', 0.0)\n",
      " ('v56_BU', 0.0) ('v56_BT', 0.0) ('v56_BS', 0.0) ('v56_BR', 0.0)\n",
      " ('v56_BQ', 0.0) ('v56_BP', 0.0) ('v56_BO', 0.0) ('v56_BH', 0.0)\n",
      " ('v56_BF', 0.0) ('v56_BE', 0.0) ('v56_BD', 0.0) ('v56_BC', 0.0)\n",
      " ('v56_B', 0.0) ('v56_AY', 0.0) ('v56_AX', 0.0) ('v56_AV', 0.0)\n",
      " ('v56_AU', 0.0) ('v56_AT', 0.0) ('v56_AP', 0.0) ('v56_AM', 0.0)\n",
      " ('v56_AJ', 0.0) ('v56_AE', 0.0) ('v56_AC', 0.0) ('v56_AB', 0.0)\n",
      " ('v56_A', 0.0) ('v47_H', 0.0) ('v47_D', 0.0) ('v47_A', 0.0) ('v3_C', 0.0)\n",
      " ('v3_B', 0.0) ('v3_A', 0.0) ('v38_9', 0.0) ('v38_8', 0.0) ('v38_7', 0.0)\n",
      " ('v38_6', 0.0) ('v38_4', 0.0) ('v38_2', 0.0) ('v38_12', 0.0)\n",
      " ('v38_10', 0.0) ('v31_B', 0.0) ('v30_B', 0.0) ('v129_8', 0.0)\n",
      " ('v129_7', 0.0) ('v129_6', 0.0) ('v129_5', 0.0) ('v129_3', 0.0)\n",
      " ('v129_11', 0.0) ('v125_BZ', 0.0) ('v125_AJ', 0.0) ('v113_AK', 0.0)\n",
      " ('v113_AA', 0.0) ('v110_C', 0.0)]\n"
     ]
    }
   ],
   "source": [
    "# (4) What are the first 5 important features?\n",
    "# print tree_model.feature_importances_\n",
    "tm_feature_importance = zip(x_train, tree_model.feature_importances_)\n",
    "#print tm_feature_importance  # My testing\n",
    "\n",
    "dtype = [('feature', 'S10'), ('importance', 'float')] # S10: 10-character string\n",
    "tm_feature_importance = np.array(tm_feature_importance, dtype = dtype)\n",
    "tm_feature_sort = np.sort(tm_feature_importance, order='importance')[::-1]\n",
    "\n",
    "print \"Top important features are: \\n\", tm_feature_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Least important features are: \n",
      "[('v50', 0.14057278011124794) ('v21', 0.0276056988711409)\n",
      " ('v66_C', 0.02596362563216391) ('v14', 0.022230693081453118)\n",
      " ('v12', 0.021499394892526922) ('v34', 0.02065936258279592)\n",
      " ('v40', 0.018446462293741736) ('v114', 0.017249637890962698)\n",
      " ('v110_A', 0.014218364452579329) ('v10', 0.01411988948921134)\n",
      " ('v66_B', 0.012613352070140872) ('v120', 0.007946379125903378)\n",
      " ('v110_B', 0.007868753523342795) ('v99', 0.007735050326966314)\n",
      " ('v39', 0.007678787548993244) ('v82', 0.007402035435686816)\n",
      " ('v85', 0.007156321053584827) ('v102', 0.007035327548171138)\n",
      " ('v70', 0.006978212538767433) ('v35', 0.006752662680096564)\n",
      " ('v124', 0.006705004538550452) ('v28', 0.006666906058355843)\n",
      " ('v6', 0.006615352558166093) ('v1', 0.00655655669345863)\n",
      " ('v88', 0.006551532907318146) ('v44', 0.006507646699740642)\n",
      " ('v57', 0.006481451893190328) ('v16', 0.0064225172458518675)\n",
      " ('v36', 0.0062418457208903155) ('v122', 0.006222718382557189)\n",
      " ('v117', 0.005923910532968088) ('v100', 0.005916954524476314)\n",
      " ('v119', 0.0058877440665214) ('v103', 0.005782432643186825)\n",
      " ('v18', 0.005775512789759797) ('v127', 0.0056548781128158915)\n",
      " ('v78', 0.005645541381203125) ('v68', 0.0055902635834024095)\n",
      " ('v87', 0.005589748703255688) ('v13', 0.005503741462001249)\n",
      " ('v98', 0.005468790228985394) ('v54', 0.005461175086507087)\n",
      " ('v27', 0.005426775724479488) ('v80', 0.0054162595979869235)\n",
      " ('v97', 0.005394191019538413) ('v7', 0.005391090816709855)\n",
      " ('v69', 0.005307446985537017) ('v90', 0.005292677994996449)\n",
      " ('v89', 0.00511461028740688) ('v9', 0.005001072549773094)\n",
      " ('v37', 0.004877108712707145) ('v20', 0.004778168742228782)\n",
      " ('v123', 0.004690753458857137) ('v126', 0.0045932584429940375)\n",
      " ('v115', 0.004589477695647284) ('v2', 0.004586323808237651)\n",
      " ('v111', 0.004569103772490096) ('v118', 0.0045145022118761)\n",
      " ('v131', 0.004478624161690178) ('v55', 0.004456191789820079)\n",
      " ('v23', 0.0044126494814948555) ('v19', 0.004388615285485699)\n",
      " ('v104', 0.004329682169739356) ('v58', 0.0043190305582738)\n",
      " ('v11', 0.004278456948920083) ('v65', 0.0042012448976643645)\n",
      " ('v92', 0.004180042829578376) ('v109', 0.004149635718817146)\n",
      " ('v60', 0.004109484266409002) ('v84', 0.004060734366658236)\n",
      " ('v81', 0.004052943830496709) ('v61', 0.0040520171828569325)\n",
      " ('v86', 0.004050941469140749) ('v108', 0.003990015381339952)\n",
      " ('v32', 0.003955811846145219) ('v101', 0.003945562186255555)\n",
      " ('v25', 0.003859039078859336) ('v45', 0.003796891004986156)\n",
      " ('v121', 0.003792122743217639) ('v73', 0.0037739050817663924)\n",
      " ('v130', 0.0037361030677097143) ('v49', 0.0037262014589628735)\n",
      " ('v43', 0.0037149683221650446) ('v26', 0.003680697272054613)\n",
      " ('v4', 0.003652734595193168) ('v77', 0.0036301053159869113)\n",
      " ('v53', 0.0034892023810072425) ('v24_E', 0.0033871824737537653)\n",
      " ('v94', 0.0033695369863644565) ('v33', 0.003283692446078393)\n",
      " ('v105', 0.0032829870737471427) ('v42', 0.0032607586597150676)\n",
      " ('v5', 0.003246971811514642) ('v15', 0.003227218107410642)\n",
      " ('v59', 0.003172114382616971) ('v24_D', 0.003160101705143208)\n",
      " ('v83', 0.0031450447750981914) ('v51', 0.003109024314933253)\n",
      " ('v93', 0.003096723389192987) ('v116', 0.003081471758391277)\n",
      " ('v8', 0.0029910395777558185) ('v63', 0.002982423253865174)\n",
      " ('v41', 0.00288717167020493) ('v67', 0.0028640837561417906)\n",
      " ('v96', 0.0028490638469155748) ('v31_A', 0.002785853209420688)\n",
      " ('v128', 0.002785313500966501) ('v48', 0.0027787758076447985)\n",
      " ('v106', 0.0027740872602618756) ('v56_BW', 0.002697900130285388)\n",
      " ('v17', 0.002626869795199413) ('v52_G', 0.002611434932298957)\n",
      " ('v52_D', 0.002590909269864851) ('v52_I', 0.00250493705010233)\n",
      " ('v29', 0.0024782069244396513) ('v52_F', 0.002464563596688499)\n",
      " ('v56_CY', 0.002452499213399697) ('v64', 0.002447792221450056)\n",
      " ('v47_C', 0.002401103055584713) ('v46', 0.0022363863762994854)\n",
      " ('v76', 0.0022013987384842445) ('v112_F', 0.0021760322113037306)\n",
      " ('v79_E', 0.002074625283812738) ('v30_C', 0.0020736404476236147)\n",
      " ('v52_C', 0.002023706349888908) ('v52_L', 0.002014516439805787)\n",
      " ('v107_C', 0.0019971601794812398) ('v72_1', 0.0019260360534891878)\n",
      " ('v52_J', 0.0018771184908828252) ('v75_D', 0.0017162193582044758)\n",
      " ('v112_A', 0.0016954523363542594) ('v66_A', 0.0016570433352735825)\n",
      " ('v95', 0.0016325455549078903) ('v24_C', 0.0016150583032418695)\n",
      " ('v52_H', 0.001611238883451781) ('v112_N', 0.00160904919062492)\n",
      " ('v91_C', 0.0015898912440196196) ('v52_B', 0.0015751760632090235)\n",
      " ('v91_B', 0.0015737947639193352) ('v52_A', 0.001559252561526826)\n",
      " ('v52_E', 0.0015205608865474086) ('v112_P', 0.0014594007715954343)\n",
      " ('v71_F', 0.0014271505662627971) ('v125_AP', 0.0013905452198913087)\n",
      " ('v125_CG', 0.0013790633980170746) ('v112_H', 0.001347496319636199)\n",
      " ('v113_G', 0.0013365129001086553) ('v71_C', 0.0013086495898531943)\n",
      " ('v125_K', 0.0013016837865918408) ('v125_BM', 0.0012897235522610594)\n",
      " ('v125_BY', 0.0012644091953432598) ('v71_B', 0.0012634480401559592)\n",
      " ('v113_AF', 0.0012581694496957582) ('v79_C', 0.0012490755022521178)\n",
      " ('v30_D', 0.001238898394023093) ('v91_A', 0.0012323045821080627)\n",
      " ('v107_B', 0.0012164458386735946) ('v24_A', 0.0011958006250108446)\n",
      " ('v125_BW', 0.0011661459962770866) ('v52_K', 0.0011651474545185793)\n",
      " ('v125_AK', 0.0011637880429488066) ('v112_O', 0.00115379323945012)\n",
      " ('v113_AG', 0.001138783183883261) ('v24_B', 0.0011285583603124632)\n",
      " ('v72_2', 0.0011237063478537067) ('v62_2', 0.0011114346542117014)\n",
      " ('v91_G', 0.001102692093737777) ('v125_E', 0.001089304775265819)\n",
      " ('v107_E', 0.0010712640994435384) ('v125_BJ', 0.0010662244374499744)\n",
      " ('v125_BL', 0.0010636074049336535) ('v75_B', 0.00106262119128099)\n",
      " ('v125_H', 0.0010538350344765797) ('v107_A', 0.0010528084491351003)\n",
      " ('v125_B', 0.0010516848047380744) ('v125_L', 0.0010387619981084553)\n",
      " ('v107_D', 0.0010260301820587626) ('v125_AC', 0.0009873881136103705)\n",
      " ('v125_V', 0.000980755290889433) ('v113_V', 0.0009736950610136194)\n",
      " ('v113_P', 0.0009735044297308775) ('v62_1', 0.000964962422971803)\n",
      " ('v56_P', 0.0009469330117820667) ('v113_AC', 0.0009457001937057738)\n",
      " ('v125_AR', 0.000938862449319565) ('v112_I', 0.0009240178538865276)\n",
      " ('v56_DY', 0.0009199530772699178) ('v79_M', 0.0009080499265625601)\n",
      " ('v125_CJ', 0.0008951590729266651) ('v113_AB', 0.0008855998776533319)\n",
      " ('v125_N', 0.000876881172503444) ('v125_T', 0.0008717267158952593)\n",
      " ('v113_W', 0.0008666957424381877) ('v125_P', 0.0008612940001000957)\n",
      " ('v125_A', 0.0008489264644274094) ('v112_E', 0.0008476693328578366)\n",
      " ('v72_0', 0.0008369132365251357) ('v125_AI', 0.0008354762677432767)\n",
      " ('v125_J', 0.0008170308968621939) ('v113_I', 0.0008115874155964353)\n",
      " ('v125_G', 0.0007982388810339868) ('v125_D', 0.0007963882952382335)\n",
      " ('v113_B', 0.0007911476239430042) ('v125_BP', 0.0007851643146683394)\n",
      " ('v30_G', 0.0007846249542283614) ('v47_I', 0.0007843559321581934)\n",
      " ('v112_K', 0.0007835231916845445) ('v125_Z', 0.000775504793428014)\n",
      " ('v125_AY', 0.0007711354236681638) ('v125_CD', 0.000766247917595965)\n",
      " ('v125_AZ', 0.0007625651782450346) ('v125_AA', 0.0007609104411389426)\n",
      " ('v125_AT', 0.0007594723347298112) ('v112_L', 0.0007579052313938098)\n",
      " ('v125_AL', 0.000752963767529758) ('v125_BD', 0.0007500914745940454)\n",
      " ('v56_BZ', 0.0007341403702255229) ('v113_AE', 0.0007336254314462978)\n",
      " ('v112_C', 0.0007315568328037231) ('v112_T', 0.0007248440932249702)\n",
      " ('v56_CN', 0.0007157494181298269) ('v56_DF', 0.0007148211077513335)\n",
      " ('v125_BX', 0.0007138215670722241) ('v91_F', 0.0007100815055512396)\n",
      " ('v112_D', 0.0007085201138558912) ('v125_CH', 0.000684274909450126)\n",
      " ('v56_DO', 0.000675677265851501) ('v125_CC', 0.0006684739748595893)\n",
      " ('v112_J', 0.0006673954494439189) ('v107_F', 0.0006571629624815338)\n",
      " ('v56_U', 0.0006544447155913747) ('v125_S', 0.0006471215811692469)\n",
      " ('v47_E', 0.0006444032093300939) ('v112_U', 0.0006426122668104031)\n",
      " ('v125_BU', 0.0006396879544594376) ('v56_AW', 0.0006393257345709384)\n",
      " ('v113_S', 0.0006337626360271073) ('v125_BK', 0.0006262282394369694)\n",
      " ('v112_V', 0.0006121184212479447) ('v125_BO', 0.0006083648285275347)\n",
      " ('v125_Q', 0.0006031504149560871) ('v56_BV', 0.0005987073596085498)\n",
      " ('v125_R', 0.0005979372891933137) ('v125_AF', 0.0005967490707854094)\n",
      " ('v125_AN', 0.0005921777594050441) ('v72_3', 0.0005915600357568925)\n",
      " ('v47_J', 0.0005904384630564839) ('v56_DI', 0.0005846685543750239)\n",
      " ('v113_AJ', 0.0005818732484957238) ('v125_BV', 0.0005645524961731641)\n",
      " ('v56_DR', 0.0005614885753689242) ('v125_CE', 0.0005525633544500873)\n",
      " ('v113_Y', 0.0005509128493402068) ('v30_E', 0.0005428115793931708)\n",
      " ('v125_AM', 0.0005403525835694748) ('v125_AS', 0.0005396573545512994)\n",
      " ('v62_3', 0.0005361892077481659) ('v125_AH', 0.0005317434925451547)\n",
      " ('v129_1', 0.0005196264859608189) ('v125_Y', 0.0005077345694462532)\n",
      " ('v56_BX', 0.0005013286448233738) ('v129_0', 0.0005012197833434263)\n",
      " ('v112_Q', 0.0004961765202183715) ('v79_B', 0.0004930068824709164)\n",
      " ('v112_G', 0.0004901267695743771) ('v125_BH', 0.00048491864072591724)\n",
      " ('v125_CF', 0.00047797210314873414) ('v125_M', 0.0004709057180693711)\n",
      " ('v79_D', 0.00046834097939294644) ('v112_R', 0.00046182608482863986)\n",
      " ('v125_BE', 0.00045285849941267283) ('v56_DP', 0.0004521880565691925)\n",
      " ('v56_DJ', 0.00044360444493014937) ('v56_R', 0.00043488426113668467)\n",
      " ('v125_AU', 0.0004336779020282589) ('v30_A', 0.00042804160872893005)\n",
      " ('v38_0', 0.00042735652264294714) ('v125_CK', 0.0004165274919275068)\n",
      " ('v56_AG', 0.00041287657316039573) ('v125_BF', 0.0004122022857930341)\n",
      " ('v113_AD', 0.0004115393448424125) ('v47_G', 0.00040968733562931915)\n",
      " ('v56_BL', 0.00039132894630057634) ('v113_AI', 0.0003841941253227995)\n",
      " ('v125_BN', 0.00037904744549378306) ('v125_X', 0.00037806908160645274)\n",
      " ('v125_AQ', 0.0003754072289482497) ('v125_AW', 0.0003750098385826627)\n",
      " ('v113_M', 0.0003725246083563161) ('v56_BJ', 0.0003711271623084278)\n",
      " ('v125_AO', 0.0003674389750584303) ('v125_C', 0.0003650761582580709)\n",
      " ('v112_M', 0.0003595619863644906) ('v125_BQ', 0.0003581662084026207)\n",
      " ('v125_CL', 0.0003508667638283471) ('v125_W', 0.000348321826045742)\n",
      " ('v113_C', 0.0003469701930336764) ('v91_E', 0.0003459445506002024)\n",
      " ('v56_G', 0.0003459219797903928) ('v79_I', 0.0003403231440873174)\n",
      " ('v56_AS', 0.0003343318188394359) ('v125_BI', 0.00033388262405681596)\n",
      " ('v56_N', 0.0003301707509321602) ('v79_P', 0.0003242380817951177)\n",
      " ('v125_CA', 0.00032416716337296673) ('v113_A', 0.0003183892659021244)\n",
      " ('v125_AG', 0.00031313182011117387) ('v113_X', 0.00030741435861918935)\n",
      " ('v112_S', 0.000307252826198232) ('v125_U', 0.0003030439523461256)\n",
      " ('v107_G', 0.0003017057136159903) ('v125_I', 0.00029890137003564114)\n",
      " ('v125_F', 0.0002882873974093546) ('v113_N', 0.00028723769901109686)\n",
      " ('v125_AE', 0.00028596489032132555) ('v56_DX', 0.0002845468134455143)\n",
      " ('v56_AN', 0.00028060940813443046) ('v125_O', 0.00027211714089926046)\n",
      " ('v79_Q', 0.0002720737388431191) ('v125_BS', 0.00027148491827048006)\n",
      " ('v125_AV', 0.00027005117607213386) ('v74_B', 0.0002635734766047766)\n",
      " ('v30_F', 0.00026310953871917076) ('v125_BG', 0.0002539408943894843)\n",
      " ('v113_L', 0.00024801560254079046) ('v56_CH', 0.0002471388283528215)\n",
      " ('v125_CB', 0.00023725907925418083) ('v113_U', 0.0002324360057342171)\n",
      " ('v56_DH', 0.00023162220431716194) ('v125_AD', 0.0002267211436122434)\n",
      " ('v112_B', 0.00022486068059685867) ('v56_AR', 0.0002183592832087654)\n",
      " ('v113_AH', 0.00021746938386726656) ('v125_BC', 0.00021670460027997128)\n",
      " ('v113_F', 0.00020125793683237807) ('v79_K', 0.00019460285247782416)\n",
      " ('v56_AO', 0.00019300843582519938) ('v47_F', 0.00018329653192968772)\n",
      " ('v125_BR', 0.000182403223021984) ('v56_AF', 0.00018136144748190158)\n",
      " ('v72_5', 0.00017978694483378999) ('v38_1', 0.00017888054207383997)\n",
      " ('v129_2', 0.00017023395940379956) ('v79_F', 0.00017010581578522478)\n",
      " ('v113_E', 0.00016876292805713698) ('v62_5', 0.0001687219418437124)\n",
      " ('v74_C', 0.0001589730773636559) ('v79_H', 0.0001579395765444527)\n",
      " ('v38_3', 0.0001550789849690711) ('v113_D', 0.00015455723391697365)\n",
      " ('v56_DS', 0.00015383909022811265) ('v56_DA', 0.0001525068492226244)\n",
      " ('v125_BT', 0.00014654710667186258) ('v125_BA', 0.00014556776633112227)\n",
      " ('v62_4', 0.00014206063801172145) ('v125_AB', 0.00013896011864699401)\n",
      " ('v31_C', 0.000137017577081107) ('v113_J', 0.00013111403560285285)\n",
      " ('v56_CA', 0.00012666790084335457) ('v47_B', 0.00011760706856479555)\n",
      " ('v113_Q', 0.00011706232698673417) ('v125_CI', 0.00010991201592491891)\n",
      " ('v38_5', 0.00010875387773739026) ('v56_AI', 0.00010873705815836412)\n",
      " ('v113_T', 0.00010826542659313722) ('v113_Z', 0.00010642225140088942)\n",
      " ('v72_6', 0.00010637982503874135) ('v113_O', 0.0001011368413904549)\n",
      " ('v56_CI', 0.00010053832552248143) ('v56_BG', 0.00010002234419194881)\n",
      " ('v79_A', 8.719300359706807e-05) ('v56_AK', 8.696652826304977e-05)\n",
      " ('v72_4', 7.198845422984585e-05) ('v113_R', 7.066694085355262e-05)\n",
      " ('v56_CC', 6.985616875486868e-05) ('v56_Y', 6.9227087174567e-05)\n",
      " ('v56_BM', 6.872678123260719e-05) ('v56_CL', 6.854657340814236e-05)\n",
      " ('v125_BB', 6.623953999111546e-05) ('v56_BA', 6.614720699594743e-05)\n",
      " ('v113_H', 6.53835341555271e-05) ('v56_C', 6.499213611546368e-05)\n",
      " ('v56_DK', 6.47072382909596e-05) ('v125_AX', 6.393678510103303e-05)\n",
      " ('v56_V', 6.228071685504864e-05) ('v56_CM', 6.228071685504864e-05)\n",
      " ('v56_CF', 6.177021917590885e-05) ('v56_CS', 5.978948818084667e-05)\n",
      " ('v56_BK', 5.978948818084667e-05) ('v79_G', 5.97827378999295e-05)\n",
      " ('v79_O', 4.98245734840389e-05) ('v56_AA', 3.7368430113029176e-05)\n",
      " ('v129_4', 3.5905040488319426e-05) ('v56_CQ', 3.569636379730199e-05)\n",
      " ('v56_BI', 3.568052573332504e-05) ('v91_D', 3.422793173752164e-05)\n",
      " ('v56_CP', 3.38321630014965e-05) ('v56_BN', 3.375466898763775e-05)\n",
      " ('v56_AZ', 3.307599281860167e-05) ('v56_Z', 3.2678465200058164e-05)\n",
      " ('v56_DM', 2.5397856171653737e-05) ('v56_DN', 2.4547716692136265e-05)\n",
      " ('v56_AH', 1.3738982797634871e-05) ('v56_AL', 8.032692815664996e-06)\n",
      " ('v56_DL', 5.743966626648846e-06) ('v79_R', 0.0) ('v79_N', 0.0)\n",
      " ('v79_L', 0.0) ('v79_J', 0.0) ('v75_C', 0.0) ('v75_A', 0.0) ('v74_A', 0.0)\n",
      " ('v72_9', 0.0) ('v72_8', 0.0) ('v72_7', 0.0)]\n"
     ]
    }
   ],
   "source": [
    "print \"\\nLeast important features are: \\n\", tm_feature_sort[0:-100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sort(tm_feature_importance, order='importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another gridSearchCV testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'criterion': 'gini', 'max_depth': 5}\n",
      "best scores:  -0.483666379533\n",
      "best model training error:  1.47896332531\n",
      "best model test error:   1.48058256035\n"
     ]
    }
   ],
   "source": [
    "# (3) Use the function grid_search.GridSearchCV to find the best parameters. \n",
    "grid_para_tree = {'criterion': ['gini', 'entropy'], 'max_depth': range(1, 21)}  # 1~20 maxdepth\n",
    "grid_search_tree = gs.GridSearchCV(tree_model, grid_para_tree, cv=5, scoring='log_loss')\n",
    "grid_search_tree.fit(x_train, y_train)\n",
    "print \"best parameters: \", grid_search_tree.best_params_\n",
    "print \"best scores: \", grid_search_tree.best_score_\n",
    "print \"best model training error: \", (1-grid_search_tree.score(x_train, y_train)) # overall accuracy on the training set:\n",
    "print \"best model test error:  \", (1-grid_search_tree.score(x_test, y_test))   # overall accuracy on the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top important features are: \n",
      "[('v50', 0.14057278011124794) ('v21', 0.0276056988711409)\n",
      " ('v66_C', 0.02596362563216391) ('v14', 0.022230693081453118)\n",
      " ('v12', 0.021499394892526922) ('v34', 0.02065936258279592)\n",
      " ('v40', 0.018446462293741736) ('v114', 0.017249637890962698)\n",
      " ('v110_A', 0.014218364452579329) ('v10', 0.01411988948921134)\n",
      " ('v66_B', 0.012613352070140872) ('v120', 0.007946379125903378)\n",
      " ('v110_B', 0.007868753523342795) ('v99', 0.007735050326966314)\n",
      " ('v39', 0.007678787548993244) ('v82', 0.007402035435686816)\n",
      " ('v85', 0.007156321053584827) ('v102', 0.007035327548171138)\n",
      " ('v70', 0.006978212538767433) ('v35', 0.006752662680096564)\n",
      " ('v124', 0.006705004538550452) ('v28', 0.006666906058355843)\n",
      " ('v6', 0.006615352558166093) ('v1', 0.00655655669345863)\n",
      " ('v88', 0.006551532907318146) ('v44', 0.006507646699740642)\n",
      " ('v57', 0.006481451893190328) ('v16', 0.0064225172458518675)\n",
      " ('v36', 0.0062418457208903155) ('v122', 0.006222718382557189)\n",
      " ('v117', 0.005923910532968088) ('v100', 0.005916954524476314)\n",
      " ('v119', 0.0058877440665214) ('v103', 0.005782432643186825)\n",
      " ('v18', 0.005775512789759797) ('v127', 0.0056548781128158915)\n",
      " ('v78', 0.005645541381203125) ('v68', 0.0055902635834024095)\n",
      " ('v87', 0.005589748703255688) ('v13', 0.005503741462001249)\n",
      " ('v98', 0.005468790228985394) ('v54', 0.005461175086507087)\n",
      " ('v27', 0.005426775724479488) ('v80', 0.0054162595979869235)\n",
      " ('v97', 0.005394191019538413) ('v7', 0.005391090816709855)\n",
      " ('v69', 0.005307446985537017) ('v90', 0.005292677994996449)\n",
      " ('v89', 0.00511461028740688) ('v9', 0.005001072549773094)\n",
      " ('v37', 0.004877108712707145) ('v20', 0.004778168742228782)\n",
      " ('v123', 0.004690753458857137) ('v126', 0.0045932584429940375)\n",
      " ('v115', 0.004589477695647284) ('v2', 0.004586323808237651)\n",
      " ('v111', 0.004569103772490096) ('v118', 0.0045145022118761)\n",
      " ('v131', 0.004478624161690178) ('v55', 0.004456191789820079)\n",
      " ('v23', 0.0044126494814948555) ('v19', 0.004388615285485699)\n",
      " ('v104', 0.004329682169739356) ('v58', 0.0043190305582738)\n",
      " ('v11', 0.004278456948920083) ('v65', 0.0042012448976643645)\n",
      " ('v92', 0.004180042829578376) ('v109', 0.004149635718817146)\n",
      " ('v60', 0.004109484266409002) ('v84', 0.004060734366658236)\n",
      " ('v81', 0.004052943830496709) ('v61', 0.0040520171828569325)\n",
      " ('v86', 0.004050941469140749) ('v108', 0.003990015381339952)\n",
      " ('v32', 0.003955811846145219) ('v101', 0.003945562186255555)\n",
      " ('v25', 0.003859039078859336) ('v45', 0.003796891004986156)\n",
      " ('v121', 0.003792122743217639) ('v73', 0.0037739050817663924)\n",
      " ('v130', 0.0037361030677097143) ('v49', 0.0037262014589628735)\n",
      " ('v43', 0.0037149683221650446) ('v26', 0.003680697272054613)\n",
      " ('v4', 0.003652734595193168) ('v77', 0.0036301053159869113)\n",
      " ('v53', 0.0034892023810072425) ('v24_E', 0.0033871824737537653)\n",
      " ('v94', 0.0033695369863644565) ('v33', 0.003283692446078393)\n",
      " ('v105', 0.0032829870737471427) ('v42', 0.0032607586597150676)\n",
      " ('v5', 0.003246971811514642) ('v15', 0.003227218107410642)\n",
      " ('v59', 0.003172114382616971) ('v24_D', 0.003160101705143208)\n",
      " ('v83', 0.0031450447750981914) ('v51', 0.003109024314933253)\n",
      " ('v93', 0.003096723389192987) ('v116', 0.003081471758391277)\n",
      " ('v8', 0.0029910395777558185) ('v63', 0.002982423253865174)\n",
      " ('v41', 0.00288717167020493) ('v67', 0.0028640837561417906)\n",
      " ('v96', 0.0028490638469155748) ('v31_A', 0.002785853209420688)\n",
      " ('v128', 0.002785313500966501) ('v48', 0.0027787758076447985)\n",
      " ('v106', 0.0027740872602618756) ('v56_BW', 0.002697900130285388)\n",
      " ('v17', 0.002626869795199413) ('v52_G', 0.002611434932298957)\n",
      " ('v52_D', 0.002590909269864851) ('v52_I', 0.00250493705010233)\n",
      " ('v29', 0.0024782069244396513) ('v52_F', 0.002464563596688499)\n",
      " ('v56_CY', 0.002452499213399697) ('v64', 0.002447792221450056)\n",
      " ('v47_C', 0.002401103055584713) ('v46', 0.0022363863762994854)\n",
      " ('v76', 0.0022013987384842445) ('v112_F', 0.0021760322113037306)\n",
      " ('v79_E', 0.002074625283812738) ('v30_C', 0.0020736404476236147)\n",
      " ('v52_C', 0.002023706349888908) ('v52_L', 0.002014516439805787)\n",
      " ('v107_C', 0.0019971601794812398) ('v72_1', 0.0019260360534891878)\n",
      " ('v52_J', 0.0018771184908828252) ('v75_D', 0.0017162193582044758)\n",
      " ('v112_A', 0.0016954523363542594) ('v66_A', 0.0016570433352735825)\n",
      " ('v95', 0.0016325455549078903) ('v24_C', 0.0016150583032418695)\n",
      " ('v52_H', 0.001611238883451781) ('v112_N', 0.00160904919062492)\n",
      " ('v91_C', 0.0015898912440196196) ('v52_B', 0.0015751760632090235)\n",
      " ('v91_B', 0.0015737947639193352) ('v52_A', 0.001559252561526826)\n",
      " ('v52_E', 0.0015205608865474086) ('v112_P', 0.0014594007715954343)\n",
      " ('v71_F', 0.0014271505662627971) ('v125_AP', 0.0013905452198913087)\n",
      " ('v125_CG', 0.0013790633980170746) ('v112_H', 0.001347496319636199)\n",
      " ('v113_G', 0.0013365129001086553) ('v71_C', 0.0013086495898531943)\n",
      " ('v125_K', 0.0013016837865918408) ('v125_BM', 0.0012897235522610594)\n",
      " ('v125_BY', 0.0012644091953432598) ('v71_B', 0.0012634480401559592)\n",
      " ('v113_AF', 0.0012581694496957582) ('v79_C', 0.0012490755022521178)\n",
      " ('v30_D', 0.001238898394023093) ('v91_A', 0.0012323045821080627)\n",
      " ('v107_B', 0.0012164458386735946) ('v24_A', 0.0011958006250108446)\n",
      " ('v125_BW', 0.0011661459962770866) ('v52_K', 0.0011651474545185793)\n",
      " ('v125_AK', 0.0011637880429488066) ('v112_O', 0.00115379323945012)\n",
      " ('v113_AG', 0.001138783183883261) ('v24_B', 0.0011285583603124632)\n",
      " ('v72_2', 0.0011237063478537067) ('v62_2', 0.0011114346542117014)\n",
      " ('v91_G', 0.001102692093737777) ('v125_E', 0.001089304775265819)\n",
      " ('v107_E', 0.0010712640994435384) ('v125_BJ', 0.0010662244374499744)\n",
      " ('v125_BL', 0.0010636074049336535) ('v75_B', 0.00106262119128099)\n",
      " ('v125_H', 0.0010538350344765797) ('v107_A', 0.0010528084491351003)\n",
      " ('v125_B', 0.0010516848047380744) ('v125_L', 0.0010387619981084553)\n",
      " ('v107_D', 0.0010260301820587626) ('v125_AC', 0.0009873881136103705)\n",
      " ('v125_V', 0.000980755290889433) ('v113_V', 0.0009736950610136194)\n",
      " ('v113_P', 0.0009735044297308775) ('v62_1', 0.000964962422971803)\n",
      " ('v56_P', 0.0009469330117820667) ('v113_AC', 0.0009457001937057738)\n",
      " ('v125_AR', 0.000938862449319565) ('v112_I', 0.0009240178538865276)\n",
      " ('v56_DY', 0.0009199530772699178) ('v79_M', 0.0009080499265625601)\n",
      " ('v125_CJ', 0.0008951590729266651) ('v113_AB', 0.0008855998776533319)\n",
      " ('v125_N', 0.000876881172503444) ('v125_T', 0.0008717267158952593)\n",
      " ('v113_W', 0.0008666957424381877) ('v125_P', 0.0008612940001000957)\n",
      " ('v125_A', 0.0008489264644274094) ('v112_E', 0.0008476693328578366)\n",
      " ('v72_0', 0.0008369132365251357) ('v125_AI', 0.0008354762677432767)\n",
      " ('v125_J', 0.0008170308968621939) ('v113_I', 0.0008115874155964353)\n",
      " ('v125_G', 0.0007982388810339868) ('v125_D', 0.0007963882952382335)\n",
      " ('v113_B', 0.0007911476239430042) ('v125_BP', 0.0007851643146683394)\n",
      " ('v30_G', 0.0007846249542283614) ('v47_I', 0.0007843559321581934)\n",
      " ('v112_K', 0.0007835231916845445) ('v125_Z', 0.000775504793428014)\n",
      " ('v125_AY', 0.0007711354236681638) ('v125_CD', 0.000766247917595965)\n",
      " ('v125_AZ', 0.0007625651782450346) ('v125_AA', 0.0007609104411389426)\n",
      " ('v125_AT', 0.0007594723347298112) ('v112_L', 0.0007579052313938098)\n",
      " ('v125_AL', 0.000752963767529758) ('v125_BD', 0.0007500914745940454)\n",
      " ('v56_BZ', 0.0007341403702255229) ('v113_AE', 0.0007336254314462978)\n",
      " ('v112_C', 0.0007315568328037231) ('v112_T', 0.0007248440932249702)\n",
      " ('v56_CN', 0.0007157494181298269) ('v56_DF', 0.0007148211077513335)\n",
      " ('v125_BX', 0.0007138215670722241) ('v91_F', 0.0007100815055512396)\n",
      " ('v112_D', 0.0007085201138558912) ('v125_CH', 0.000684274909450126)\n",
      " ('v56_DO', 0.000675677265851501) ('v125_CC', 0.0006684739748595893)\n",
      " ('v112_J', 0.0006673954494439189) ('v107_F', 0.0006571629624815338)\n",
      " ('v56_U', 0.0006544447155913747) ('v125_S', 0.0006471215811692469)\n",
      " ('v47_E', 0.0006444032093300939) ('v112_U', 0.0006426122668104031)\n",
      " ('v125_BU', 0.0006396879544594376) ('v56_AW', 0.0006393257345709384)\n",
      " ('v113_S', 0.0006337626360271073) ('v125_BK', 0.0006262282394369694)\n",
      " ('v112_V', 0.0006121184212479447) ('v125_BO', 0.0006083648285275347)\n",
      " ('v125_Q', 0.0006031504149560871) ('v56_BV', 0.0005987073596085498)\n",
      " ('v125_R', 0.0005979372891933137) ('v125_AF', 0.0005967490707854094)\n",
      " ('v125_AN', 0.0005921777594050441) ('v72_3', 0.0005915600357568925)\n",
      " ('v47_J', 0.0005904384630564839) ('v56_DI', 0.0005846685543750239)\n",
      " ('v113_AJ', 0.0005818732484957238) ('v125_BV', 0.0005645524961731641)\n",
      " ('v56_DR', 0.0005614885753689242) ('v125_CE', 0.0005525633544500873)\n",
      " ('v113_Y', 0.0005509128493402068) ('v30_E', 0.0005428115793931708)\n",
      " ('v125_AM', 0.0005403525835694748) ('v125_AS', 0.0005396573545512994)\n",
      " ('v62_3', 0.0005361892077481659) ('v125_AH', 0.0005317434925451547)\n",
      " ('v129_1', 0.0005196264859608189) ('v125_Y', 0.0005077345694462532)\n",
      " ('v56_BX', 0.0005013286448233738) ('v129_0', 0.0005012197833434263)\n",
      " ('v112_Q', 0.0004961765202183715) ('v79_B', 0.0004930068824709164)\n",
      " ('v112_G', 0.0004901267695743771) ('v125_BH', 0.00048491864072591724)\n",
      " ('v125_CF', 0.00047797210314873414) ('v125_M', 0.0004709057180693711)\n",
      " ('v79_D', 0.00046834097939294644) ('v112_R', 0.00046182608482863986)\n",
      " ('v125_BE', 0.00045285849941267283) ('v56_DP', 0.0004521880565691925)\n",
      " ('v56_DJ', 0.00044360444493014937) ('v56_R', 0.00043488426113668467)\n",
      " ('v125_AU', 0.0004336779020282589) ('v30_A', 0.00042804160872893005)\n",
      " ('v38_0', 0.00042735652264294714) ('v125_CK', 0.0004165274919275068)\n",
      " ('v56_AG', 0.00041287657316039573) ('v125_BF', 0.0004122022857930341)\n",
      " ('v113_AD', 0.0004115393448424125) ('v47_G', 0.00040968733562931915)\n",
      " ('v56_BL', 0.00039132894630057634) ('v113_AI', 0.0003841941253227995)\n",
      " ('v125_BN', 0.00037904744549378306) ('v125_X', 0.00037806908160645274)\n",
      " ('v125_AQ', 0.0003754072289482497) ('v125_AW', 0.0003750098385826627)\n",
      " ('v113_M', 0.0003725246083563161) ('v56_BJ', 0.0003711271623084278)\n",
      " ('v125_AO', 0.0003674389750584303) ('v125_C', 0.0003650761582580709)\n",
      " ('v112_M', 0.0003595619863644906) ('v125_BQ', 0.0003581662084026207)\n",
      " ('v125_CL', 0.0003508667638283471) ('v125_W', 0.000348321826045742)\n",
      " ('v113_C', 0.0003469701930336764) ('v91_E', 0.0003459445506002024)\n",
      " ('v56_G', 0.0003459219797903928) ('v79_I', 0.0003403231440873174)\n",
      " ('v56_AS', 0.0003343318188394359) ('v125_BI', 0.00033388262405681596)\n",
      " ('v56_N', 0.0003301707509321602) ('v79_P', 0.0003242380817951177)\n",
      " ('v125_CA', 0.00032416716337296673) ('v113_A', 0.0003183892659021244)\n",
      " ('v125_AG', 0.00031313182011117387) ('v113_X', 0.00030741435861918935)\n",
      " ('v112_S', 0.000307252826198232) ('v125_U', 0.0003030439523461256)\n",
      " ('v107_G', 0.0003017057136159903) ('v125_I', 0.00029890137003564114)\n",
      " ('v125_F', 0.0002882873974093546) ('v113_N', 0.00028723769901109686)\n",
      " ('v125_AE', 0.00028596489032132555) ('v56_DX', 0.0002845468134455143)\n",
      " ('v56_AN', 0.00028060940813443046) ('v125_O', 0.00027211714089926046)\n",
      " ('v79_Q', 0.0002720737388431191) ('v125_BS', 0.00027148491827048006)\n",
      " ('v125_AV', 0.00027005117607213386) ('v74_B', 0.0002635734766047766)\n",
      " ('v30_F', 0.00026310953871917076) ('v125_BG', 0.0002539408943894843)\n",
      " ('v113_L', 0.00024801560254079046) ('v56_CH', 0.0002471388283528215)\n",
      " ('v125_CB', 0.00023725907925418083) ('v113_U', 0.0002324360057342171)\n",
      " ('v56_DH', 0.00023162220431716194) ('v125_AD', 0.0002267211436122434)\n",
      " ('v112_B', 0.00022486068059685867) ('v56_AR', 0.0002183592832087654)\n",
      " ('v113_AH', 0.00021746938386726656) ('v125_BC', 0.00021670460027997128)\n",
      " ('v113_F', 0.00020125793683237807) ('v79_K', 0.00019460285247782416)\n",
      " ('v56_AO', 0.00019300843582519938) ('v47_F', 0.00018329653192968772)\n",
      " ('v125_BR', 0.000182403223021984) ('v56_AF', 0.00018136144748190158)\n",
      " ('v72_5', 0.00017978694483378999) ('v38_1', 0.00017888054207383997)\n",
      " ('v129_2', 0.00017023395940379956) ('v79_F', 0.00017010581578522478)\n",
      " ('v113_E', 0.00016876292805713698) ('v62_5', 0.0001687219418437124)\n",
      " ('v74_C', 0.0001589730773636559) ('v79_H', 0.0001579395765444527)\n",
      " ('v38_3', 0.0001550789849690711) ('v113_D', 0.00015455723391697365)\n",
      " ('v56_DS', 0.00015383909022811265) ('v56_DA', 0.0001525068492226244)\n",
      " ('v125_BT', 0.00014654710667186258) ('v125_BA', 0.00014556776633112227)\n",
      " ('v62_4', 0.00014206063801172145) ('v125_AB', 0.00013896011864699401)\n",
      " ('v31_C', 0.000137017577081107) ('v113_J', 0.00013111403560285285)\n",
      " ('v56_CA', 0.00012666790084335457) ('v47_B', 0.00011760706856479555)\n",
      " ('v113_Q', 0.00011706232698673417) ('v125_CI', 0.00010991201592491891)\n",
      " ('v38_5', 0.00010875387773739026) ('v56_AI', 0.00010873705815836412)\n",
      " ('v113_T', 0.00010826542659313722) ('v113_Z', 0.00010642225140088942)\n",
      " ('v72_6', 0.00010637982503874135) ('v113_O', 0.0001011368413904549)\n",
      " ('v56_CI', 0.00010053832552248143) ('v56_BG', 0.00010002234419194881)\n",
      " ('v79_A', 8.719300359706807e-05) ('v56_AK', 8.696652826304977e-05)\n",
      " ('v72_4', 7.198845422984585e-05) ('v113_R', 7.066694085355262e-05)\n",
      " ('v56_CC', 6.985616875486868e-05) ('v56_Y', 6.9227087174567e-05)\n",
      " ('v56_BM', 6.872678123260719e-05) ('v56_CL', 6.854657340814236e-05)\n",
      " ('v125_BB', 6.623953999111546e-05) ('v56_BA', 6.614720699594743e-05)\n",
      " ('v113_H', 6.53835341555271e-05) ('v56_C', 6.499213611546368e-05)\n",
      " ('v56_DK', 6.47072382909596e-05) ('v125_AX', 6.393678510103303e-05)\n",
      " ('v56_V', 6.228071685504864e-05) ('v56_CM', 6.228071685504864e-05)\n",
      " ('v56_CF', 6.177021917590885e-05) ('v56_CS', 5.978948818084667e-05)\n",
      " ('v56_BK', 5.978948818084667e-05) ('v79_G', 5.97827378999295e-05)\n",
      " ('v79_O', 4.98245734840389e-05) ('v56_AA', 3.7368430113029176e-05)\n",
      " ('v129_4', 3.5905040488319426e-05) ('v56_CQ', 3.569636379730199e-05)\n",
      " ('v56_BI', 3.568052573332504e-05) ('v91_D', 3.422793173752164e-05)\n",
      " ('v56_CP', 3.38321630014965e-05) ('v56_BN', 3.375466898763775e-05)\n",
      " ('v56_AZ', 3.307599281860167e-05) ('v56_Z', 3.2678465200058164e-05)\n",
      " ('v56_DM', 2.5397856171653737e-05) ('v56_DN', 2.4547716692136265e-05)\n",
      " ('v56_AH', 1.3738982797634871e-05) ('v56_AL', 8.032692815664996e-06)\n",
      " ('v56_DL', 5.743966626648846e-06) ('v79_R', 0.0) ('v79_N', 0.0)\n",
      " ('v79_L', 0.0) ('v79_J', 0.0) ('v75_C', 0.0) ('v75_A', 0.0) ('v74_A', 0.0)\n",
      " ('v72_9', 0.0) ('v72_8', 0.0) ('v72_7', 0.0) ('v72_12', 0.0)\n",
      " ('v72_11', 0.0) ('v72_10', 0.0) ('v71_L', 0.0) ('v71_K', 0.0)\n",
      " ('v71_I', 0.0) ('v71_G', 0.0) ('v71_D', 0.0) ('v71_A', 0.0) ('v62_7', 0.0)\n",
      " ('v62_6', 0.0) ('v62_0', 0.0) ('v56_X', 0.0) ('v56_W', 0.0) ('v56_T', 0.0)\n",
      " ('v56_Q', 0.0) ('v56_O', 0.0) ('v56_M', 0.0) ('v56_L', 0.0) ('v56_I', 0.0)\n",
      " ('v56_H', 0.0) ('v56_F', 0.0) ('v56_E', 0.0) ('v56_DZ', 0.0)\n",
      " ('v56_DW', 0.0) ('v56_DV', 0.0) ('v56_DU', 0.0) ('v56_DT', 0.0)\n",
      " ('v56_DQ', 0.0) ('v56_DG', 0.0) ('v56_DE', 0.0) ('v56_DD', 0.0)\n",
      " ('v56_DC', 0.0) ('v56_DB', 0.0) ('v56_D', 0.0) ('v56_CZ', 0.0)\n",
      " ('v56_CX', 0.0) ('v56_CW', 0.0) ('v56_CV', 0.0) ('v56_CT', 0.0)\n",
      " ('v56_CO', 0.0) ('v56_CK', 0.0) ('v56_CJ', 0.0) ('v56_CG', 0.0)\n",
      " ('v56_CE', 0.0) ('v56_CD', 0.0) ('v56_CB', 0.0) ('v56_BY', 0.0)\n",
      " ('v56_BU', 0.0) ('v56_BT', 0.0) ('v56_BS', 0.0) ('v56_BR', 0.0)\n",
      " ('v56_BQ', 0.0) ('v56_BP', 0.0) ('v56_BO', 0.0) ('v56_BH', 0.0)\n",
      " ('v56_BF', 0.0) ('v56_BE', 0.0) ('v56_BD', 0.0) ('v56_BC', 0.0)\n",
      " ('v56_B', 0.0) ('v56_AY', 0.0) ('v56_AX', 0.0) ('v56_AV', 0.0)\n",
      " ('v56_AU', 0.0) ('v56_AT', 0.0) ('v56_AP', 0.0) ('v56_AM', 0.0)\n",
      " ('v56_AJ', 0.0) ('v56_AE', 0.0) ('v56_AC', 0.0) ('v56_AB', 0.0)\n",
      " ('v56_A', 0.0) ('v47_H', 0.0) ('v47_D', 0.0) ('v47_A', 0.0) ('v3_C', 0.0)\n",
      " ('v3_B', 0.0) ('v3_A', 0.0) ('v38_9', 0.0) ('v38_8', 0.0) ('v38_7', 0.0)\n",
      " ('v38_6', 0.0) ('v38_4', 0.0) ('v38_2', 0.0) ('v38_12', 0.0)\n",
      " ('v38_10', 0.0) ('v31_B', 0.0) ('v30_B', 0.0) ('v129_8', 0.0)\n",
      " ('v129_7', 0.0) ('v129_6', 0.0) ('v129_5', 0.0) ('v129_3', 0.0)\n",
      " ('v129_11', 0.0) ('v125_BZ', 0.0) ('v125_AJ', 0.0) ('v113_AK', 0.0)\n",
      " ('v113_AA', 0.0) ('v110_C', 0.0)]\n"
     ]
    }
   ],
   "source": [
    "# (4) Top important features?\n",
    "# print tree_model.feature_importances_\n",
    "tm_feature_importance = zip(x_train, tree_model.feature_importances_)\n",
    "\n",
    "dtype = [('feature', 'S10'), ('importance', 'float')] # S10: 10-character string\n",
    "tm_feature_importance = np.array(tm_feature_importance, dtype = dtype)\n",
    "tm_feature_sort = np.sort(tm_feature_importance, order='importance')[::-1]\n",
    "\n",
    "print \"Top important features are: \\n\", tm_feature_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([('v110_C', 0.0), ('v113_AA', 0.0), ('v113_AK', 0.0),\n",
       "       ('v125_AJ', 0.0), ('v125_BZ', 0.0), ('v129_11', 0.0),\n",
       "       ('v129_3', 0.0), ('v129_5', 0.0), ('v129_6', 0.0), ('v129_7', 0.0),\n",
       "       ('v129_8', 0.0), ('v30_B', 0.0), ('v31_B', 0.0), ('v38_10', 0.0),\n",
       "       ('v38_12', 0.0), ('v38_2', 0.0), ('v38_4', 0.0), ('v38_6', 0.0),\n",
       "       ('v38_7', 0.0), ('v38_8', 0.0), ('v38_9', 0.0), ('v3_A', 0.0),\n",
       "       ('v3_B', 0.0), ('v3_C', 0.0), ('v47_A', 0.0), ('v47_D', 0.0),\n",
       "       ('v47_H', 0.0), ('v56_A', 0.0), ('v56_AB', 0.0), ('v56_AC', 0.0),\n",
       "       ('v56_AE', 0.0), ('v56_AJ', 0.0), ('v56_AM', 0.0), ('v56_AP', 0.0),\n",
       "       ('v56_AT', 0.0), ('v56_AU', 0.0), ('v56_AV', 0.0), ('v56_AX', 0.0),\n",
       "       ('v56_AY', 0.0), ('v56_B', 0.0), ('v56_BC', 0.0), ('v56_BD', 0.0),\n",
       "       ('v56_BE', 0.0), ('v56_BF', 0.0), ('v56_BH', 0.0), ('v56_BO', 0.0),\n",
       "       ('v56_BP', 0.0), ('v56_BQ', 0.0), ('v56_BR', 0.0), ('v56_BS', 0.0),\n",
       "       ('v56_BT', 0.0), ('v56_BU', 0.0), ('v56_BY', 0.0), ('v56_CB', 0.0),\n",
       "       ('v56_CD', 0.0), ('v56_CE', 0.0), ('v56_CG', 0.0), ('v56_CJ', 0.0),\n",
       "       ('v56_CK', 0.0), ('v56_CO', 0.0), ('v56_CT', 0.0), ('v56_CV', 0.0),\n",
       "       ('v56_CW', 0.0), ('v56_CX', 0.0), ('v56_CZ', 0.0), ('v56_D', 0.0),\n",
       "       ('v56_DB', 0.0), ('v56_DC', 0.0), ('v56_DD', 0.0), ('v56_DE', 0.0),\n",
       "       ('v56_DG', 0.0), ('v56_DQ', 0.0), ('v56_DT', 0.0), ('v56_DU', 0.0),\n",
       "       ('v56_DV', 0.0), ('v56_DW', 0.0), ('v56_DZ', 0.0), ('v56_E', 0.0),\n",
       "       ('v56_F', 0.0), ('v56_H', 0.0), ('v56_I', 0.0), ('v56_L', 0.0),\n",
       "       ('v56_M', 0.0), ('v56_O', 0.0), ('v56_Q', 0.0), ('v56_T', 0.0),\n",
       "       ('v56_W', 0.0), ('v56_X', 0.0), ('v62_0', 0.0), ('v62_6', 0.0),\n",
       "       ('v62_7', 0.0), ('v71_A', 0.0), ('v71_D', 0.0), ('v71_G', 0.0),\n",
       "       ('v71_I', 0.0), ('v71_K', 0.0), ('v71_L', 0.0), ('v72_10', 0.0),\n",
       "       ('v72_11', 0.0), ('v72_12', 0.0), ('v72_7', 0.0), ('v72_8', 0.0),\n",
       "       ('v72_9', 0.0), ('v74_A', 0.0), ('v75_A', 0.0), ('v75_C', 0.0),\n",
       "       ('v79_J', 0.0), ('v79_L', 0.0), ('v79_N', 0.0), ('v79_R', 0.0),\n",
       "       ('v56_DL', 5.743966626648846e-06),\n",
       "       ('v56_AL', 8.032692815664996e-06),\n",
       "       ('v56_AH', 1.3738982797634871e-05),\n",
       "       ('v56_DN', 2.4547716692136265e-05),\n",
       "       ('v56_DM', 2.5397856171653737e-05),\n",
       "       ('v56_Z', 3.2678465200058164e-05),\n",
       "       ('v56_AZ', 3.307599281860167e-05),\n",
       "       ('v56_BN', 3.375466898763775e-05), ('v56_CP', 3.38321630014965e-05),\n",
       "       ('v91_D', 3.422793173752164e-05), ('v56_BI', 3.568052573332504e-05),\n",
       "       ('v56_CQ', 3.569636379730199e-05),\n",
       "       ('v129_4', 3.5905040488319426e-05),\n",
       "       ('v56_AA', 3.7368430113029176e-05), ('v79_O', 4.98245734840389e-05),\n",
       "       ('v79_G', 5.97827378999295e-05), ('v56_BK', 5.978948818084667e-05),\n",
       "       ('v56_CS', 5.978948818084667e-05),\n",
       "       ('v56_CF', 6.177021917590885e-05),\n",
       "       ('v56_CM', 6.228071685504864e-05), ('v56_V', 6.228071685504864e-05),\n",
       "       ('v125_AX', 6.393678510103303e-05),\n",
       "       ('v56_DK', 6.47072382909596e-05), ('v56_C', 6.499213611546368e-05),\n",
       "       ('v113_H', 6.53835341555271e-05), ('v56_BA', 6.614720699594743e-05),\n",
       "       ('v125_BB', 6.623953999111546e-05),\n",
       "       ('v56_CL', 6.854657340814236e-05),\n",
       "       ('v56_BM', 6.872678123260719e-05), ('v56_Y', 6.9227087174567e-05),\n",
       "       ('v56_CC', 6.985616875486868e-05),\n",
       "       ('v113_R', 7.066694085355262e-05), ('v72_4', 7.198845422984585e-05),\n",
       "       ('v56_AK', 8.696652826304977e-05), ('v79_A', 8.719300359706807e-05),\n",
       "       ('v56_BG', 0.00010002234419194881),\n",
       "       ('v56_CI', 0.00010053832552248143),\n",
       "       ('v113_O', 0.0001011368413904549),\n",
       "       ('v72_6', 0.00010637982503874135),\n",
       "       ('v113_Z', 0.00010642225140088942),\n",
       "       ('v113_T', 0.00010826542659313722),\n",
       "       ('v56_AI', 0.00010873705815836412),\n",
       "       ('v38_5', 0.00010875387773739026),\n",
       "       ('v125_CI', 0.00010991201592491891),\n",
       "       ('v113_Q', 0.00011706232698673417),\n",
       "       ('v47_B', 0.00011760706856479555),\n",
       "       ('v56_CA', 0.00012666790084335457),\n",
       "       ('v113_J', 0.00013111403560285285), ('v31_C', 0.000137017577081107),\n",
       "       ('v125_AB', 0.00013896011864699401),\n",
       "       ('v62_4', 0.00014206063801172145),\n",
       "       ('v125_BA', 0.00014556776633112227),\n",
       "       ('v125_BT', 0.00014654710667186258),\n",
       "       ('v56_DA', 0.0001525068492226244),\n",
       "       ('v56_DS', 0.00015383909022811265),\n",
       "       ('v113_D', 0.00015455723391697365),\n",
       "       ('v38_3', 0.0001550789849690711), ('v79_H', 0.0001579395765444527),\n",
       "       ('v74_C', 0.0001589730773636559), ('v62_5', 0.0001687219418437124),\n",
       "       ('v113_E', 0.00016876292805713698),\n",
       "       ('v79_F', 0.00017010581578522478),\n",
       "       ('v129_2', 0.00017023395940379956),\n",
       "       ('v38_1', 0.00017888054207383997),\n",
       "       ('v72_5', 0.00017978694483378999),\n",
       "       ('v56_AF', 0.00018136144748190158),\n",
       "       ('v125_BR', 0.000182403223021984),\n",
       "       ('v47_F', 0.00018329653192968772),\n",
       "       ('v56_AO', 0.00019300843582519938),\n",
       "       ('v79_K', 0.00019460285247782416),\n",
       "       ('v113_F', 0.00020125793683237807),\n",
       "       ('v125_BC', 0.00021670460027997128),\n",
       "       ('v113_AH', 0.00021746938386726656),\n",
       "       ('v56_AR', 0.0002183592832087654),\n",
       "       ('v112_B', 0.00022486068059685867),\n",
       "       ('v125_AD', 0.0002267211436122434),\n",
       "       ('v56_DH', 0.00023162220431716194),\n",
       "       ('v113_U', 0.0002324360057342171),\n",
       "       ('v125_CB', 0.00023725907925418083),\n",
       "       ('v56_CH', 0.0002471388283528215),\n",
       "       ('v113_L', 0.00024801560254079046),\n",
       "       ('v125_BG', 0.0002539408943894843),\n",
       "       ('v30_F', 0.00026310953871917076), ('v74_B', 0.0002635734766047766),\n",
       "       ('v125_AV', 0.00027005117607213386),\n",
       "       ('v125_BS', 0.00027148491827048006),\n",
       "       ('v79_Q', 0.0002720737388431191),\n",
       "       ('v125_O', 0.00027211714089926046),\n",
       "       ('v56_AN', 0.00028060940813443046),\n",
       "       ('v56_DX', 0.0002845468134455143),\n",
       "       ('v125_AE', 0.00028596489032132555),\n",
       "       ('v113_N', 0.00028723769901109686),\n",
       "       ('v125_F', 0.0002882873974093546),\n",
       "       ('v125_I', 0.00029890137003564114),\n",
       "       ('v107_G', 0.0003017057136159903),\n",
       "       ('v125_U', 0.0003030439523461256), ('v112_S', 0.000307252826198232),\n",
       "       ('v113_X', 0.00030741435861918935),\n",
       "       ('v125_AG', 0.00031313182011117387),\n",
       "       ('v113_A', 0.0003183892659021244),\n",
       "       ('v125_CA', 0.00032416716337296673),\n",
       "       ('v79_P', 0.0003242380817951177), ('v56_N', 0.0003301707509321602),\n",
       "       ('v125_BI', 0.00033388262405681596),\n",
       "       ('v56_AS', 0.0003343318188394359), ('v79_I', 0.0003403231440873174),\n",
       "       ('v56_G', 0.0003459219797903928), ('v91_E', 0.0003459445506002024),\n",
       "       ('v113_C', 0.0003469701930336764), ('v125_W', 0.000348321826045742),\n",
       "       ('v125_CL', 0.0003508667638283471),\n",
       "       ('v125_BQ', 0.0003581662084026207),\n",
       "       ('v112_M', 0.0003595619863644906),\n",
       "       ('v125_C', 0.0003650761582580709),\n",
       "       ('v125_AO', 0.0003674389750584303),\n",
       "       ('v56_BJ', 0.0003711271623084278),\n",
       "       ('v113_M', 0.0003725246083563161),\n",
       "       ('v125_AW', 0.0003750098385826627),\n",
       "       ('v125_AQ', 0.0003754072289482497),\n",
       "       ('v125_X', 0.00037806908160645274),\n",
       "       ('v125_BN', 0.00037904744549378306),\n",
       "       ('v113_AI', 0.0003841941253227995),\n",
       "       ('v56_BL', 0.00039132894630057634),\n",
       "       ('v47_G', 0.00040968733562931915),\n",
       "       ('v113_AD', 0.0004115393448424125),\n",
       "       ('v125_BF', 0.0004122022857930341),\n",
       "       ('v56_AG', 0.00041287657316039573),\n",
       "       ('v125_CK', 0.0004165274919275068),\n",
       "       ('v38_0', 0.00042735652264294714),\n",
       "       ('v30_A', 0.00042804160872893005),\n",
       "       ('v125_AU', 0.0004336779020282589),\n",
       "       ('v56_R', 0.00043488426113668467),\n",
       "       ('v56_DJ', 0.00044360444493014937),\n",
       "       ('v56_DP', 0.0004521880565691925),\n",
       "       ('v125_BE', 0.00045285849941267283),\n",
       "       ('v112_R', 0.00046182608482863986),\n",
       "       ('v79_D', 0.00046834097939294644),\n",
       "       ('v125_M', 0.0004709057180693711),\n",
       "       ('v125_CF', 0.00047797210314873414),\n",
       "       ('v125_BH', 0.00048491864072591724),\n",
       "       ('v112_G', 0.0004901267695743771), ('v79_B', 0.0004930068824709164),\n",
       "       ('v112_Q', 0.0004961765202183715),\n",
       "       ('v129_0', 0.0005012197833434263),\n",
       "       ('v56_BX', 0.0005013286448233738),\n",
       "       ('v125_Y', 0.0005077345694462532),\n",
       "       ('v129_1', 0.0005196264859608189),\n",
       "       ('v125_AH', 0.0005317434925451547),\n",
       "       ('v62_3', 0.0005361892077481659),\n",
       "       ('v125_AS', 0.0005396573545512994),\n",
       "       ('v125_AM', 0.0005403525835694748),\n",
       "       ('v30_E', 0.0005428115793931708), ('v113_Y', 0.0005509128493402068),\n",
       "       ('v125_CE', 0.0005525633544500873),\n",
       "       ('v56_DR', 0.0005614885753689242),\n",
       "       ('v125_BV', 0.0005645524961731641),\n",
       "       ('v113_AJ', 0.0005818732484957238),\n",
       "       ('v56_DI', 0.0005846685543750239), ('v47_J', 0.0005904384630564839),\n",
       "       ('v72_3', 0.0005915600357568925),\n",
       "       ('v125_AN', 0.0005921777594050441),\n",
       "       ('v125_AF', 0.0005967490707854094),\n",
       "       ('v125_R', 0.0005979372891933137),\n",
       "       ('v56_BV', 0.0005987073596085498),\n",
       "       ('v125_Q', 0.0006031504149560871),\n",
       "       ('v125_BO', 0.0006083648285275347),\n",
       "       ('v112_V', 0.0006121184212479447),\n",
       "       ('v125_BK', 0.0006262282394369694),\n",
       "       ('v113_S', 0.0006337626360271073),\n",
       "       ('v56_AW', 0.0006393257345709384),\n",
       "       ('v125_BU', 0.0006396879544594376),\n",
       "       ('v112_U', 0.0006426122668104031), ('v47_E', 0.0006444032093300939),\n",
       "       ('v125_S', 0.0006471215811692469), ('v56_U', 0.0006544447155913747),\n",
       "       ('v107_F', 0.0006571629624815338),\n",
       "       ('v112_J', 0.0006673954494439189),\n",
       "       ('v125_CC', 0.0006684739748595893),\n",
       "       ('v56_DO', 0.000675677265851501), ('v125_CH', 0.000684274909450126),\n",
       "       ('v112_D', 0.0007085201138558912), ('v91_F', 0.0007100815055512396),\n",
       "       ('v125_BX', 0.0007138215670722241),\n",
       "       ('v56_DF', 0.0007148211077513335),\n",
       "       ('v56_CN', 0.0007157494181298269),\n",
       "       ('v112_T', 0.0007248440932249702),\n",
       "       ('v112_C', 0.0007315568328037231),\n",
       "       ('v113_AE', 0.0007336254314462978),\n",
       "       ('v56_BZ', 0.0007341403702255229),\n",
       "       ('v125_BD', 0.0007500914745940454),\n",
       "       ('v125_AL', 0.000752963767529758),\n",
       "       ('v112_L', 0.0007579052313938098),\n",
       "       ('v125_AT', 0.0007594723347298112),\n",
       "       ('v125_AA', 0.0007609104411389426),\n",
       "       ('v125_AZ', 0.0007625651782450346),\n",
       "       ('v125_CD', 0.000766247917595965),\n",
       "       ('v125_AY', 0.0007711354236681638),\n",
       "       ('v125_Z', 0.000775504793428014), ('v112_K', 0.0007835231916845445),\n",
       "       ('v47_I', 0.0007843559321581934), ('v30_G', 0.0007846249542283614),\n",
       "       ('v125_BP', 0.0007851643146683394),\n",
       "       ('v113_B', 0.0007911476239430042),\n",
       "       ('v125_D', 0.0007963882952382335),\n",
       "       ('v125_G', 0.0007982388810339868),\n",
       "       ('v113_I', 0.0008115874155964353),\n",
       "       ('v125_J', 0.0008170308968621939),\n",
       "       ('v125_AI', 0.0008354762677432767),\n",
       "       ('v72_0', 0.0008369132365251357), ('v112_E', 0.0008476693328578366),\n",
       "       ('v125_A', 0.0008489264644274094),\n",
       "       ('v125_P', 0.0008612940001000957),\n",
       "       ('v113_W', 0.0008666957424381877),\n",
       "       ('v125_T', 0.0008717267158952593), ('v125_N', 0.000876881172503444),\n",
       "       ('v113_AB', 0.0008855998776533319),\n",
       "       ('v125_CJ', 0.0008951590729266651),\n",
       "       ('v79_M', 0.0009080499265625601), ('v56_DY', 0.0009199530772699178),\n",
       "       ('v112_I', 0.0009240178538865276),\n",
       "       ('v125_AR', 0.000938862449319565),\n",
       "       ('v113_AC', 0.0009457001937057738),\n",
       "       ('v56_P', 0.0009469330117820667), ('v62_1', 0.000964962422971803),\n",
       "       ('v113_P', 0.0009735044297308775),\n",
       "       ('v113_V', 0.0009736950610136194), ('v125_V', 0.000980755290889433),\n",
       "       ('v125_AC', 0.0009873881136103705),\n",
       "       ('v107_D', 0.0010260301820587626),\n",
       "       ('v125_L', 0.0010387619981084553),\n",
       "       ('v125_B', 0.0010516848047380744),\n",
       "       ('v107_A', 0.0010528084491351003),\n",
       "       ('v125_H', 0.0010538350344765797), ('v75_B', 0.00106262119128099),\n",
       "       ('v125_BL', 0.0010636074049336535),\n",
       "       ('v125_BJ', 0.0010662244374499744),\n",
       "       ('v107_E', 0.0010712640994435384), ('v125_E', 0.001089304775265819),\n",
       "       ('v91_G', 0.001102692093737777), ('v62_2', 0.0011114346542117014),\n",
       "       ('v72_2', 0.0011237063478537067), ('v24_B', 0.0011285583603124632),\n",
       "       ('v113_AG', 0.001138783183883261), ('v112_O', 0.00115379323945012),\n",
       "       ('v125_AK', 0.0011637880429488066),\n",
       "       ('v52_K', 0.0011651474545185793),\n",
       "       ('v125_BW', 0.0011661459962770866),\n",
       "       ('v24_A', 0.0011958006250108446), ('v107_B', 0.0012164458386735946),\n",
       "       ('v91_A', 0.0012323045821080627), ('v30_D', 0.001238898394023093),\n",
       "       ('v79_C', 0.0012490755022521178),\n",
       "       ('v113_AF', 0.0012581694496957582),\n",
       "       ('v71_B', 0.0012634480401559592),\n",
       "       ('v125_BY', 0.0012644091953432598),\n",
       "       ('v125_BM', 0.0012897235522610594),\n",
       "       ('v125_K', 0.0013016837865918408), ('v71_C', 0.0013086495898531943),\n",
       "       ('v113_G', 0.0013365129001086553), ('v112_H', 0.001347496319636199),\n",
       "       ('v125_CG', 0.0013790633980170746),\n",
       "       ('v125_AP', 0.0013905452198913087),\n",
       "       ('v71_F', 0.0014271505662627971), ('v112_P', 0.0014594007715954343),\n",
       "       ('v52_E', 0.0015205608865474086), ('v52_A', 0.001559252561526826),\n",
       "       ('v91_B', 0.0015737947639193352), ('v52_B', 0.0015751760632090235),\n",
       "       ('v91_C', 0.0015898912440196196), ('v112_N', 0.00160904919062492),\n",
       "       ('v52_H', 0.001611238883451781), ('v24_C', 0.0016150583032418695),\n",
       "       ('v95', 0.0016325455549078903), ('v66_A', 0.0016570433352735825),\n",
       "       ('v112_A', 0.0016954523363542594), ('v75_D', 0.0017162193582044758),\n",
       "       ('v52_J', 0.0018771184908828252), ('v72_1', 0.0019260360534891878),\n",
       "       ('v107_C', 0.0019971601794812398), ('v52_L', 0.002014516439805787),\n",
       "       ('v52_C', 0.002023706349888908), ('v30_C', 0.0020736404476236147),\n",
       "       ('v79_E', 0.002074625283812738), ('v112_F', 0.0021760322113037306),\n",
       "       ('v76', 0.0022013987384842445), ('v46', 0.0022363863762994854),\n",
       "       ('v47_C', 0.002401103055584713), ('v64', 0.002447792221450056),\n",
       "       ('v56_CY', 0.002452499213399697), ('v52_F', 0.002464563596688499),\n",
       "       ('v29', 0.0024782069244396513), ('v52_I', 0.00250493705010233),\n",
       "       ('v52_D', 0.002590909269864851), ('v52_G', 0.002611434932298957),\n",
       "       ('v17', 0.002626869795199413), ('v56_BW', 0.002697900130285388),\n",
       "       ('v106', 0.0027740872602618756), ('v48', 0.0027787758076447985),\n",
       "       ('v128', 0.002785313500966501), ('v31_A', 0.002785853209420688),\n",
       "       ('v96', 0.0028490638469155748), ('v67', 0.0028640837561417906),\n",
       "       ('v41', 0.00288717167020493), ('v63', 0.002982423253865174),\n",
       "       ('v8', 0.0029910395777558185), ('v116', 0.003081471758391277),\n",
       "       ('v93', 0.003096723389192987), ('v51', 0.003109024314933253),\n",
       "       ('v83', 0.0031450447750981914), ('v24_D', 0.003160101705143208),\n",
       "       ('v59', 0.003172114382616971), ('v15', 0.003227218107410642),\n",
       "       ('v5', 0.003246971811514642), ('v42', 0.0032607586597150676),\n",
       "       ('v105', 0.0032829870737471427), ('v33', 0.003283692446078393),\n",
       "       ('v94', 0.0033695369863644565), ('v24_E', 0.0033871824737537653),\n",
       "       ('v53', 0.0034892023810072425), ('v77', 0.0036301053159869113),\n",
       "       ('v4', 0.003652734595193168), ('v26', 0.003680697272054613),\n",
       "       ('v43', 0.0037149683221650446), ('v49', 0.0037262014589628735),\n",
       "       ('v130', 0.0037361030677097143), ('v73', 0.0037739050817663924),\n",
       "       ('v121', 0.003792122743217639), ('v45', 0.003796891004986156),\n",
       "       ('v25', 0.003859039078859336), ('v101', 0.003945562186255555),\n",
       "       ('v32', 0.003955811846145219), ('v108', 0.003990015381339952),\n",
       "       ('v86', 0.004050941469140749), ('v61', 0.0040520171828569325),\n",
       "       ('v81', 0.004052943830496709), ('v84', 0.004060734366658236),\n",
       "       ('v60', 0.004109484266409002), ('v109', 0.004149635718817146),\n",
       "       ('v92', 0.004180042829578376), ('v65', 0.0042012448976643645),\n",
       "       ('v11', 0.004278456948920083), ('v58', 0.0043190305582738),\n",
       "       ('v104', 0.004329682169739356), ('v19', 0.004388615285485699),\n",
       "       ('v23', 0.0044126494814948555), ('v55', 0.004456191789820079),\n",
       "       ('v131', 0.004478624161690178), ('v118', 0.0045145022118761),\n",
       "       ('v111', 0.004569103772490096), ('v2', 0.004586323808237651),\n",
       "       ('v115', 0.004589477695647284), ('v126', 0.0045932584429940375),\n",
       "       ('v123', 0.004690753458857137), ('v20', 0.004778168742228782),\n",
       "       ('v37', 0.004877108712707145), ('v9', 0.005001072549773094),\n",
       "       ('v89', 0.00511461028740688), ('v90', 0.005292677994996449),\n",
       "       ('v69', 0.005307446985537017), ('v7', 0.005391090816709855),\n",
       "       ('v97', 0.005394191019538413), ('v80', 0.0054162595979869235),\n",
       "       ('v27', 0.005426775724479488), ('v54', 0.005461175086507087),\n",
       "       ('v98', 0.005468790228985394), ('v13', 0.005503741462001249),\n",
       "       ('v87', 0.005589748703255688), ('v68', 0.0055902635834024095),\n",
       "       ('v78', 0.005645541381203125), ('v127', 0.0056548781128158915),\n",
       "       ('v18', 0.005775512789759797), ('v103', 0.005782432643186825),\n",
       "       ('v119', 0.0058877440665214), ('v100', 0.005916954524476314),\n",
       "       ('v117', 0.005923910532968088), ('v122', 0.006222718382557189),\n",
       "       ('v36', 0.0062418457208903155), ('v16', 0.0064225172458518675),\n",
       "       ('v57', 0.006481451893190328), ('v44', 0.006507646699740642),\n",
       "       ('v88', 0.006551532907318146), ('v1', 0.00655655669345863),\n",
       "       ('v6', 0.006615352558166093), ('v28', 0.006666906058355843),\n",
       "       ('v124', 0.006705004538550452), ('v35', 0.006752662680096564),\n",
       "       ('v70', 0.006978212538767433), ('v102', 0.007035327548171138),\n",
       "       ('v85', 0.007156321053584827), ('v82', 0.007402035435686816),\n",
       "       ('v39', 0.007678787548993244), ('v99', 0.007735050326966314),\n",
       "       ('v110_B', 0.007868753523342795), ('v120', 0.007946379125903378),\n",
       "       ('v66_B', 0.012613352070140872), ('v10', 0.01411988948921134),\n",
       "       ('v110_A', 0.014218364452579329), ('v114', 0.017249637890962698),\n",
       "       ('v40', 0.018446462293741736), ('v34', 0.02065936258279592),\n",
       "       ('v12', 0.021499394892526922), ('v14', 0.022230693081453118),\n",
       "       ('v66_C', 0.02596362563216391), ('v21', 0.0276056988711409),\n",
       "       ('v50', 0.14057278011124794)], \n",
       "      dtype=[('feature', 'S10'), ('importance', '<f8')])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"Least important features oreded\"\n",
    "np.sort(tm_feature_importance, order='importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
