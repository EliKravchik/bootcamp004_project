{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satishjoshi/anaconda/lib/python2.7/site-packages/bs4/__init__.py:166: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "To get rid of this warning, change this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import unicodedata as ud\n",
    "import re\n",
    "text = requests.get('http://www.ttnews.com/fuel/indexf.aspx')\n",
    "text = text.text\n",
    "text = BeautifulSoup(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "header = text.find_all(lambda Tag: Tag.name=='td' and Tag.get('bgcolor') =='#c0c0c0')\n",
    "top_header_lst = []\n",
    "for w in header:\n",
    "    t = w.get_text()\n",
    "    t = ud.normalize('NFKD', t).encode('ascii', 'ignore')\n",
    "    top_header_lst.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_links = text.select('table tr table tr td a')\n",
    "links = []\n",
    "link_texts = []\n",
    "for w in all_links:\n",
    "    if (re.search('\\/fuel\\/', str(w)) != None) and (re.search('\\\"_blank\\\"', str(w)) != None):\n",
    "        t = w.get('href')\n",
    "        #bad links from the page itself :(\n",
    "        t = t.replace(\".asp.htm\", \".asp\")        \n",
    "        links.append(t)\n",
    "        t = w.get_text()\n",
    "        t = ud.normalize('NFKD', t).encode('ascii', 'ignore')\n",
    "        link_texts.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_labels_links = text.select('table tr table tr td td')\n",
    "years = []\n",
    "for w in all_labels_links:\n",
    "    if (re.search('<td>', str(w)) != None) and (re.search('2[0-9][0-9][0-9]', str(w)) != None) and \\\n",
    "    (re.search('\\/fuel\\/', str(w)) == None):\n",
    "        t = w.get_text()\n",
    "        t = ud.normalize('NFKD', t).encode('ascii', 'ignore')\n",
    "        years.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "price_table_columns = ['Index']+top_header_lst + ['DOELink','COMDataLink','Updated']\n",
    "price_table = pd.DataFrame(data=np.zeros((0,len(price_table_columns))), columns=price_table_columns)\n",
    "\n",
    "data_dict = {}\n",
    "i = 0\n",
    "for index,item in enumerate(years):\n",
    "    data_dict['Index'] = index\n",
    "    data_dict[top_header_lst[0]] = item\n",
    "    data_dict[top_header_lst[1]] = link_texts[index*2]\n",
    "    data_dict[top_header_lst[2]] = link_texts[index*2+1]\n",
    "    data_dict['DOELink'] = links[index*2]\n",
    "    data_dict['COMDataLink'] = links[index*2+1]\n",
    "    data_dict['Updated'] = 'No'\n",
    "\n",
    "    single = pd.DataFrame([data_dict], columns=price_table_columns)\n",
    "    price_table = price_table.append(single)\n",
    "price_table.to_csv('price_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_header(data, lst, tag_color = 1):\n",
    "#    lst = []\n",
    "#    header_row = soup.find('bgColor'= \"#ffffcc\")\n",
    "    if tag_color == 1:\n",
    "        header_row = data.find_all(lambda Tag: Tag.name=='tr' and Tag.get('bgcolor') \\\n",
    "                               in {'#ffffcc',\"#FFFFCC\"})\n",
    "    else:\n",
    "        header_row = data.find_all(lambda Tag: Tag.name=='tr'  and Tag.get('b'))\n",
    "#    print header_row\n",
    "    for row in header_row:\n",
    "#        print row\n",
    "        col = row.findAll('td')\n",
    "#        print col\n",
    "        for td in col:\n",
    "#            print td\n",
    "            t = td.get_text().rstrip(\"\\r\\n \")\n",
    "            t = t.replace(\"\\r\\n                                  \", \"\")\n",
    "            t = t.replace(\" \\r\\n      \", \" \")\n",
    "            t = t.replace(\"\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\",\"\")\n",
    "            t = t.replace(\" \\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\", \" \")\n",
    "            t = ud.normalize('NFKD', t).encode('ascii', 'ignore')   \n",
    "#            print \"Value is %s\" %t\n",
    "            lst.append(t)\n",
    "#print header_list\n",
    "\n",
    "#    return lst\n",
    "    return\n",
    "\n",
    "def row_colors(Tag):\n",
    "    return Tag.get('bgcolor') in {'#CCCCCC','#FFFFFF','cccccc','#ffffff''#cccccc'}\n",
    "\n",
    "def modify_values(value):\n",
    "    if re.search('/', value)==None:\n",
    "        if re.search('\\.$', value):\n",
    "            return float(value[:-1])  \n",
    "        else:\n",
    "            return float(value) \n",
    "    else:\n",
    "        return value\n",
    "\n",
    "def get_prices(data, lst):\n",
    "#    lst = []\n",
    "    t = data.find_all(lambda Tag: Tag.name=='tr' and row_colors(Tag))\n",
    "#    print \"I am in get prices\\n\"\n",
    "#    print t\n",
    "    for w in t:\n",
    "        value = w.get_text().strip('\\n ')\n",
    "#        print value\n",
    "        if value.find('/') != -1 :\n",
    "            date = ud.normalize('NFKD', value).encode('ascii', 'ignore')\n",
    "#        print date\n",
    "        lst.append(map(lambda x: modify_values(x),date.split()))\n",
    "#    return lst\n",
    "    return\n",
    "def get_doe_yearly_prices(data, header, prices, tag_color = 1):\n",
    "#print type(yearly_fuel_price_DOE)\n",
    "#    data = data.text\n",
    "#print type(yearly_fuel_price_DOE)\n",
    "#    data = BeautifulSoup(data)\n",
    "#print yearly_fuel_price_DOE.prettify()\n",
    "\n",
    "#header_list = []\n",
    "#price_list = []\n",
    "    get_header(data, header, tag_color)\n",
    "#    print \"Get header is done\\n\"\n",
    "    get_prices(data, prices)\n",
    "#    print \"Get prices is done\\n\"\n",
    "    return  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "def get_yearly_doe_prices(link, header, prices, tag_color = 1): \n",
    "    yearly_fuel_price_DOE = requests.get(link)\n",
    "    yearly_fuel_price_DOE = yearly_fuel_price_DOE.text\n",
    "    yearly_fuel_price_DOE = BeautifulSoup(yearly_fuel_price_DOE)\n",
    "    get_doe_yearly_prices(yearly_fuel_price_DOE, header, prices, tag_color)\n",
    "\n",
    "\n",
    "print type(price_table)\n",
    "DOE_header_columns = ['Year', 'Link', 'Date', 'U.S. Average', 'East Coast', \\\n",
    "    'New England', 'Central Atlantic', 'Lower Atlantic', 'Midwest', 'Gulf Coast', \\\n",
    "    'Rocky Mountain', 'West Coast', 'California']\n",
    "\n",
    "DOE_header = pd.DataFrame(data=np.zeros((0,len(DOE_header_columns))), columns=DOE_header_columns)\n",
    "DOE_values = pd.DataFrame(data=np.zeros((0,len(DOE_header_columns))), columns=DOE_header_columns)\n",
    "\n",
    "for index, row in price_table.iterrows():\n",
    "    header_list2 = []\n",
    "    price_list2 = []\n",
    "    if row['Year'] in  ['2000', '2001', '2002']:\n",
    "        get_yearly_doe_prices (row[\"DOELink\"], header_list2, price_list2, 0)\n",
    "    else:\n",
    "        get_yearly_doe_prices (row[\"DOELink\"], header_list2, price_list2)\n",
    "    header_dict = {}\n",
    "    value_dict = {}\n",
    "    header_dict['Year'] = row['Year']\n",
    "    header_dict['Link'] = row[\"DOELink\"]\n",
    "    value_dict['Year'] = row['Year']\n",
    "    value_dict['Link'] = row[\"DOELink\"]\n",
    "    for index, region in enumerate(header_list2):\n",
    "        header_dict[DOE_header_columns[index+2]] = region\n",
    "    single = pd.DataFrame([header_dict], columns=DOE_header_columns)\n",
    "    DOE_header = DOE_header.append(single)\n",
    "    for index, value_lst in enumerate(price_list2):\n",
    "        for index, value in enumerate(value_lst):\n",
    "            value_dict[DOE_header_columns[index+2]] = value\n",
    "        one_week = pd.DataFrame([value_dict], columns=DOE_header_columns)\n",
    "        DOE_values = DOE_values.append(one_week)\n",
    "DOE_header.to_csv('DOE_header.csv')\n",
    "DOE_values.to_csv('DOE_values.csv')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
